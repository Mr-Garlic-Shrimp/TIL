{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深層学習ノートブック-13 DatasetとDataLoader\n",
    "Pytorchにおいて、学習用のデータセットを読み込んだり前処理を効率的に行う仕組み。  \n",
    "* Dataset\n",
    "    * torch.utils.data.Dataset\n",
    "    * pytorchには既にいくつものDatasetが用意されている\n",
    "        * https://pytorch.org/vision/stable/datasets.html\n",
    "    * カスタムで作ることも可能\n",
    "        * torch.uDls.data.Datasetを継承する\n",
    "        * __len__と__getitem__をオーバーライドする。\n",
    "\n",
    "* DataLoader\n",
    "    * torch.utils.data.DataLoader\n",
    "    * Datasetからバッチ単位でデータを効率的に読み込むためのイテレータを提供\n",
    "    * 複数のスレッドによる並列処理に対応している\n",
    "        * 深層学習において、GPUは学習に関する処理、CPUはディスクにあるデータをミニバッチ単位で読み込みを行っている。  \n",
    "        CPUによるデータ（ミニバッチ）の読み込みがGPUの学習よりも遅いと、GPUがデータ読み込み待ちになってしまい、タイムロスが生じる。  \n",
    "        DataLoaderはミニバッチをCPUから並列で読み込むことで、データ読み込み時間の短縮を図ることが出来る。\n",
    "\n",
    "参考：  \n",
    "* [Udemy講座：「①米国AI開発者がやさしく教える深層学習超入門第一弾【Pythonで実践】」](https://www.udemy.com/course/deeplearning1/learn/lecture/40143418)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Pytorchが提供するMNISTデータのDatasetを使う\n",
    "* torchvisionというPytorchと互換性があるCVのためのライブラリを用いる。\n",
    "* MNISTデータはtorchvision.datasetsのうちの一つのDatasetクラス。  \n",
    "* 使い方\n",
    "    * torchvision.datasets.MNISTクラスでインスタンスを生成\n",
    "        * root: データを保存するディレクトリを指定\n",
    "        * train: Trueなら学習データを，Falseならテストデータをロード\n",
    "        * download: Trueなら，rootに指定したディレクトリにダウンロードし，  \n",
    "            既にデータがある場合はそのデータを使用する\n",
    "    * []でindexingによりデータとラベルをtuple形式で取得する．\n",
    "    * データはPIL(Pillow)で返ってくるので，tensorへtransformが必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNISTの学習データを./mnist_dataへダウンロード\n",
    "train_dataset = torchvision.datasets.MNIST('./mnist_data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# サイズを確認すると５６バイトしかない。\n",
    "# train_datasetにダウンロードしたデータが入るわけではない。実態はあくまでディスクにある。\n",
    "sys.getsizeof(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ自体は60000件あることが分かる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28>, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データとラベル（目的変数）をtupleで取得\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# １枚目の画像と正解ラベルを格納\n",
    "image, label = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA90lEQVR4AWNgGMyAWUhIqK5jvdSy/9/rQe5kgTlWjs3KRiAYxHsyKfDzxYMgFiOIAALDvfwQBsO/pK8Mz97fhPLAlNDtvyBwbNv3j8jCUHbAnOy/f89yM2jPwiLJwMc4628UqgQTnPvp/0eGFAQXLg5lcO/764YuhuArf3y4IAfmfoQwlBX44e/fckkMYaiA7q6/f6dJ45IViP3zdzcuSQaGn39/OkBl4WEL4euFmLIwXDuETav6lKfAIPy1DYucRNFdUPCe9MOUE3e6CpI6FogZSEKrwbFyOIATQ5v5mkcgXV9auVGlwK4NDGRguL75b88HVDla8QBFF16ADQA8sQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データを確認\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正解ラベル\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIL形式はJupyterLabではそのまま描画できる。  \n",
    "もちろん下記のようにmatplotlibでも可能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f33423d1110>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "Datasetで読み込んだデータセット（PIL）をTensorに変換したり、  \n",
    "標準化・正規化等の前処理出来るモジュール。\n",
    "\n",
    "* torchvision.transforms: 画像関連で使用する便利な変換機能を提供\n",
    "    * __.ToTensor()__: [0, 255]の(H, W, C(=Channel))のPILやNumpyArrayをtensorに変換するクラス\n",
    "        * インスタンスを生成しPIL形式のデータを渡してcallする\n",
    "        * 変換後は[0., 1.]の(C, H, W)のtensorとなる\n",
    "    * __.Normalize()__: 平均と標準偏差を使って画像データを標準化する\n",
    "        * mean: それぞれのchannelのmeanをtupleで渡す\n",
    "        * std: それぞれのchannelのstdをtupleで渡す\n",
    "        * 正規化として使われることが多い (0~1 -> -1~1)\n",
    "    * __.Compose()__: 複数のtransformをまとめる\n",
    "        * 複数のtransformsのインスタンスをリストにして渡す\n",
    "        * datasets.<クラス名>のtransform引数に渡すことで，データをロードする際に変換処理を行ってくれる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DatasetをTensorに変換。一度ToTensorのインスタンスを作ってからimageを渡してcallする\n",
    "image_tensor = transforms.ToTensor()(image)\n",
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorに変換されている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3342509110>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# チャネルファースト(C, H, W)になっているので、そのままimshowには入れられないため、2Rankにして渡している。\n",
    "plt.imshow(image_tensor[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -0.8588,\n",
       "          -0.8588, -0.8588, -0.0118,  0.0667,  0.3725, -0.7961,  0.3020,\n",
       "           1.0000,  0.9373, -0.0039, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -0.7647, -0.7176, -0.2627,  0.2078,  0.3333,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.7647,  0.3490,  0.9843,\n",
       "           0.8980,  0.5294, -0.4980, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.6157,  0.8667,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9686, -0.2706, -0.3569, -0.3569,\n",
       "          -0.5608, -0.6941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.8588,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.5529,  0.4275,  0.9373,  0.8902, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -0.3725,  0.2235, -0.1608,  0.9843,  0.9843,  0.6078,\n",
       "          -0.9137, -1.0000, -0.6627,  0.2078, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -0.8902, -0.9922,  0.2078,  0.9843, -0.2941,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000,  0.0902,  0.9843,  0.4902,\n",
       "          -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9137,  0.4902,  0.9843,\n",
       "          -0.4510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7255,  0.8902,\n",
       "           0.7647,  0.2549, -0.1529, -0.9922, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3647,\n",
       "           0.8824,  0.9843,  0.9843, -0.0667, -0.8039, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.6471,  0.4588,  0.9843,  0.9843,  0.1765, -0.7882, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -0.8745, -0.2706,  0.9765,  0.9843,  0.4667, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000,  0.9529,  0.9843,  0.9529, -0.4980,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.6392,  0.0196,  0.4353,  0.9843,  0.9843,  0.6235, -0.9843,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6941,  0.1608,\n",
       "           0.7961,  0.9843,  0.9843,  0.9843,  0.9608,  0.4275, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -0.8118, -0.1059,  0.7333,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.5765, -0.3882, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -0.8196, -0.4824,  0.6706,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.5529, -0.3647, -0.9843, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8588,\n",
       "           0.3412,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.5294,\n",
       "          -0.3725, -0.9294, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.5686,  0.3490,  0.7725,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9137,  0.0431, -0.9137,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000,  0.0667,  0.9843,  0.9843,\n",
       "           0.9843,  0.6627,  0.0588,  0.0353, -0.8745, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 標準化.平均と標準偏差を決め打ちでタプルで渡すことに注意\n",
    "normalized_image_tensor = transforms.Normalize((0.5, ), (0.5) )(image_tensor)\n",
    "normalized_image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToTensorで変換後のTensorは0,1の値を持つので、平均・標準偏差0.5を指定すると、  \n",
    "-1,1で正規化される。これは深層学習の前処理としてよく使われるテクニックである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .Compose()でTensorへの変換と標準化をまとめてできる\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,) , (0.5,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -0.8588,\n",
       "          -0.8588, -0.8588, -0.0118,  0.0667,  0.3725, -0.7961,  0.3020,\n",
       "           1.0000,  0.9373, -0.0039, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -0.7647, -0.7176, -0.2627,  0.2078,  0.3333,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.7647,  0.3490,  0.9843,\n",
       "           0.8980,  0.5294, -0.4980, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.6157,  0.8667,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9686, -0.2706, -0.3569, -0.3569,\n",
       "          -0.5608, -0.6941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.8588,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.5529,  0.4275,  0.9373,  0.8902, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -0.3725,  0.2235, -0.1608,  0.9843,  0.9843,  0.6078,\n",
       "          -0.9137, -1.0000, -0.6627,  0.2078, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -0.8902, -0.9922,  0.2078,  0.9843, -0.2941,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000,  0.0902,  0.9843,  0.4902,\n",
       "          -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9137,  0.4902,  0.9843,\n",
       "          -0.4510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7255,  0.8902,\n",
       "           0.7647,  0.2549, -0.1529, -0.9922, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3647,\n",
       "           0.8824,  0.9843,  0.9843, -0.0667, -0.8039, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.6471,  0.4588,  0.9843,  0.9843,  0.1765, -0.7882, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -0.8745, -0.2706,  0.9765,  0.9843,  0.4667, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000,  0.9529,  0.9843,  0.9529, -0.4980,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.6392,  0.0196,  0.4353,  0.9843,  0.9843,  0.6235, -0.9843,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6941,  0.1608,\n",
       "           0.7961,  0.9843,  0.9843,  0.9843,  0.9608,  0.4275, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -0.8118, -0.1059,  0.7333,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.5765, -0.3882, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -0.8196, -0.4824,  0.6706,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.5529, -0.3647, -0.9843, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8588,\n",
       "           0.3412,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.5294,\n",
       "          -0.3725, -0.9294, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.5686,  0.3490,  0.7725,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9137,  0.0431, -0.9137,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000,  0.0667,  0.9843,  0.9843,\n",
       "           0.9843,  0.6627,  0.0588,  0.0353, -0.8745, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のようにリストとして、操作を渡すことで前処理をまとめて実行してくれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets読み込みの際にtransform引数に渡すことで前処理された状態でデータを利用できる\n",
    "train_dataset = torchvision.datasets.MNIST('./mnist_data', train=True, download=True, transform=transform)\n",
    "val_dataset = torchvision.datasets.MNIST('./mnist_data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -0.8588,\n",
       "          -0.8588, -0.8588, -0.0118,  0.0667,  0.3725, -0.7961,  0.3020,\n",
       "           1.0000,  0.9373, -0.0039, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -0.7647, -0.7176, -0.2627,  0.2078,  0.3333,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.7647,  0.3490,  0.9843,\n",
       "           0.8980,  0.5294, -0.4980, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.6157,  0.8667,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9686, -0.2706, -0.3569, -0.3569,\n",
       "          -0.5608, -0.6941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.8588,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.5529,  0.4275,  0.9373,  0.8902, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -0.3725,  0.2235, -0.1608,  0.9843,  0.9843,  0.6078,\n",
       "          -0.9137, -1.0000, -0.6627,  0.2078, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -0.8902, -0.9922,  0.2078,  0.9843, -0.2941,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000,  0.0902,  0.9843,  0.4902,\n",
       "          -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9137,  0.4902,  0.9843,\n",
       "          -0.4510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7255,  0.8902,\n",
       "           0.7647,  0.2549, -0.1529, -0.9922, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3647,\n",
       "           0.8824,  0.9843,  0.9843, -0.0667, -0.8039, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.6471,  0.4588,  0.9843,  0.9843,  0.1765, -0.7882, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -0.8745, -0.2706,  0.9765,  0.9843,  0.4667, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000,  0.9529,  0.9843,  0.9529, -0.4980,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.6392,  0.0196,  0.4353,  0.9843,  0.9843,  0.6235, -0.9843,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6941,  0.1608,\n",
       "           0.7961,  0.9843,  0.9843,  0.9843,  0.9608,  0.4275, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -0.8118, -0.1059,  0.7333,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.5765, -0.3882, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -0.8196, -0.4824,  0.6706,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.5529, -0.3647, -0.9843, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8588,\n",
       "           0.3412,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.5294,\n",
       "          -0.3725, -0.9294, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.5686,  0.3490,  0.7725,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9137,  0.0431, -0.9137,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000,  0.0667,  0.9843,  0.9843,\n",
       "           0.9843,  0.6627,  0.0588,  0.0353, -0.8745, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_dataset[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train=Falseにして読み込めば、学習データと同じ前処理を検証データにも適用できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ DataLoaderでDatasetからデータを読み込む\n",
    "上記で作成したtrain_datasetとval_datasetからデータを読み込む。  \n",
    "\n",
    "* torch.utils.data.DataLoaderクラスでインスタンスを生成\n",
    "    * dataset: ロード対象となるDatasetオブジェクトを指定\n",
    "    * batch_size: ミニバッチ学習におけるバッチサイズ\n",
    "    * shuffle: Trueの場合，各epochでシャッフルする\n",
    "    * 検証データの場合，shuffleは不要\n",
    "    * num_workers: データロードに使用するスレッドの数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=10,  num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoaderはGeneratorの形で返ってくるので、イテレーションが可能。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]]]),\n",
       " tensor([9, 5, 3, 1, 6, 4, 8, 3, 5, 1])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "イテレーションを実行すると、10個のデータ（バッチサイズと同じ）とその教師ラベルが返ってくる。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# バッチを一つ取り出す\n",
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチサイズ、チャネル数、画像の高さ、画像の幅のシェイプ(b, c, h, w)となっている。  \n",
    "画像データを直接扱えるようなモデルはこのシェイプのデータを学習データとすることが多い。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 62, 242])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt.imshowで可視化するために、Rank3のtensorに変換する\n",
    "grid_images = torchvision.utils.make_grid(images)\n",
    "grid_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make_gridを(b, c, h, w)の画像データに適用すると、  \n",
    "Rank3のtensorに変換されるが、(c, h, w)の形式で返されるので、  \n",
    "imshowで可視化するために(h, w, c)に変換する必要あり。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f065dc96a10>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 今、imagesは正規化して読み込んでいるので、正規化前に戻して生の状態を可視化\n",
    "grid_images = (grid_images + 0.5) * 2\n",
    "\n",
    "plt.imshow(torch.permute(grid_images, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 4, 0, 8, 0, 2, 0, 5, 8, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 対応するラベルを見る\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ DataLoaderをMLPの学習ループに組み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3, 4])\n",
      "tensor([[[[ 0.0875,  1.0362, -0.4055, -0.2601],\n",
      "          [-1.4979, -0.4754,  0.7581,  1.8832],\n",
      "          [ 1.9809, -0.3505, -0.2142, -0.3367]],\n",
      "\n",
      "         [[ 0.3087, -2.3483, -1.0049,  0.2769],\n",
      "          [-0.6463, -1.1599, -1.0690,  1.0481],\n",
      "          [ 1.4669,  0.6049, -1.1171,  1.1328]]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((1, 2, 3, 4))\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_1(nn.Module):\n",
    "    def __init__(self, num_in, num_hidden, num_out):\n",
    "        # 親クラスのinitを呼び出す。\n",
    "        super().__init__()\n",
    "        # nn.Flattenにより[b, c, h, w] -> [b, c x h x w]（ミニバッチサイズ, 画像の特徴量数の積）に変換\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(num_in, num_hidden)\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_out)\n",
    "\n",
    "    # nn.Moduleにもforwardメソッドがあり、ここでオーバーライドしている。\n",
    "    def forward(self, x):\n",
    "        # デバッグ用\n",
    "        # z1 = self.linear_1(z)\n",
    "        # a1 = F.relu(z1)\n",
    "        # z2 = self.linear_2(a1)\n",
    "        # 隠れ層の線形変換 →ReLu適用→ 隠れ層の線形変換を一気にやっている。\n",
    "        z = self.linear_2( F.relu( self.linear_1(x)) )\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "補足：なぜ c x h x wの形状にするのか  \n",
    "DataLoaderで返されるデータの形状は[b, c, h, w]なので、nn.Linearで線形変換するためには、  \n",
    "入力データをRank2に変換する必要があるため。  \n",
    "nn.Linearに渡すデータ$X$のRank1は学習データの数であり、Rank2は特徴量数に相当するのであったから、  \n",
    "画像データにおける特徴量数＝チャネル数×縦サイズ×横サイズをのshapeを渡す必要がある。  \n",
    "nn.Flattenは画像の学習によく使うので覚えておくとよい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データと検証データのDataLoaderを定義\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,  num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNISTデータセットの読み込み\n",
    "dataset = datasets.load_digits()\n",
    "X = torch.tensor( dataset.data , dtype=torch.float32) \n",
    "y = torch.tensor( dataset.target)\n",
    "# ★ F.cross_entropyの仕様的にはone_hotの形にする必要はない\n",
    "# y = F.one_hot(y, num_classes=10) \n",
    "\n",
    "# hold-out\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 標準化\n",
    "train_mean, train_std = X_train.mean(), X_train.std()\n",
    "X_train = (X_train - train_mean) / train_std\n",
    "X_val = (X_val - train_mean) / train_std\n",
    "\n",
    "# モデルのコンストラクタに渡す引数を定義\n",
    "num_in = 64\n",
    "num_hidden = 30\n",
    "num_out = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル定義（２層のMLP）\n",
    "MLP_model = MLP_1(num_in=num_in, num_hidden=num_hidden, num_out=num_out)\n",
    "# requires_grad_をTrueに設定。最後に_がつくのは設定するという意味。\n",
    "MLP_model.requires_grad_(True)\n",
    "\n",
    "# torch.optimを使ってOptimizerを定義\n",
    "optim_torch = optim.SGD(MLP_model.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0: {'Loss_train': 2.1334453026453652, 'Loss_val': 1.9139227867126465, 'Accuracy': 0.5638889074325562}\n",
      "epoch_1: {'Loss_train': 1.6540952603022256, 'Loss_val': 1.3794052600860596, 'Accuracy': 0.7638888955116272}\n",
      "epoch_2: {'Loss_train': 1.143251978026496, 'Loss_val': 0.9410049319267273, 'Accuracy': 0.8777777552604675}\n",
      "epoch_3: {'Loss_train': 0.783967755900489, 'Loss_val': 0.6448764801025391, 'Accuracy': 0.9138888716697693}\n",
      "epoch_4: {'Loss_train': 0.570439213514328, 'Loss_val': 0.4894690215587616, 'Accuracy': 0.925000011920929}\n",
      "epoch_5: {'Loss_train': 0.4404057184855143, 'Loss_val': 0.39046478271484375, 'Accuracy': 0.9277777671813965}\n",
      "epoch_6: {'Loss_train': 0.3618222494920095, 'Loss_val': 0.3285788595676422, 'Accuracy': 0.9361110925674438}\n",
      "epoch_7: {'Loss_train': 0.30878644386927284, 'Loss_val': 0.28534895181655884, 'Accuracy': 0.9444444179534912}\n",
      "epoch_8: {'Loss_train': 0.27153442137771183, 'Loss_val': 0.2566598355770111, 'Accuracy': 0.9444444179534912}\n",
      "epoch_9: {'Loss_train': 0.2430220713218053, 'Loss_val': 0.23574458062648773, 'Accuracy': 0.9444444179534912}\n",
      "epoch_10: {'Loss_train': 0.22089975476264953, 'Loss_val': 0.2180788218975067, 'Accuracy': 0.9444444179534912}\n",
      "epoch_11: {'Loss_train': 0.20403868605693182, 'Loss_val': 0.20231252908706665, 'Accuracy': 0.9472222328186035}\n",
      "epoch_12: {'Loss_train': 0.1902547828025288, 'Loss_val': 0.19157980382442474, 'Accuracy': 0.9472222328186035}\n",
      "epoch_13: {'Loss_train': 0.17826640390687518, 'Loss_val': 0.18311144411563873, 'Accuracy': 0.9472222328186035}\n",
      "epoch_14: {'Loss_train': 0.16718190270993444, 'Loss_val': 0.17702269554138184, 'Accuracy': 0.949999988079071}\n",
      "epoch_15: {'Loss_train': 0.15907934026585685, 'Loss_val': 0.16641703248023987, 'Accuracy': 0.9583333134651184}\n",
      "epoch_16: {'Loss_train': 0.1515469540324476, 'Loss_val': 0.1598421186208725, 'Accuracy': 0.9583333134651184}\n",
      "epoch_17: {'Loss_train': 0.14566726759076118, 'Loss_val': 0.15696237981319427, 'Accuracy': 0.9583333134651184}\n",
      "epoch_18: {'Loss_train': 0.13905693938334782, 'Loss_val': 0.14852114021778107, 'Accuracy': 0.9611111283302307}\n",
      "epoch_19: {'Loss_train': 0.13313504341575835, 'Loss_val': 0.14677222073078156, 'Accuracy': 0.9611111283302307}\n",
      "epoch_20: {'Loss_train': 0.12814902149968677, 'Loss_val': 0.14166800677776337, 'Accuracy': 0.9611111283302307}\n",
      "epoch_21: {'Loss_train': 0.12304608060253991, 'Loss_val': 0.1385210007429123, 'Accuracy': 0.9611111283302307}\n",
      "epoch_22: {'Loss_train': 0.1193233847618103, 'Loss_val': 0.13524608314037323, 'Accuracy': 0.9638888835906982}\n",
      "epoch_23: {'Loss_train': 0.11468246099021699, 'Loss_val': 0.13274140655994415, 'Accuracy': 0.9611111283302307}\n",
      "epoch_24: {'Loss_train': 0.11111891306936741, 'Loss_val': 0.1313425451517105, 'Accuracy': 0.9611111283302307}\n",
      "epoch_25: {'Loss_train': 0.10775135540299946, 'Loss_val': 0.13009978830814362, 'Accuracy': 0.9611111283302307}\n",
      "epoch_26: {'Loss_train': 0.10503682552112473, 'Loss_val': 0.12526001036167145, 'Accuracy': 0.9638888835906982}\n",
      "epoch_27: {'Loss_train': 0.10200385111901496, 'Loss_val': 0.12426850944757462, 'Accuracy': 0.9666666388511658}\n",
      "epoch_28: {'Loss_train': 0.09882482232318984, 'Loss_val': 0.12233224511146545, 'Accuracy': 0.9611111283302307}\n",
      "epoch_29: {'Loss_train': 0.09621496328877079, 'Loss_val': 0.1236833781003952, 'Accuracy': 0.9638888835906982}\n",
      "epoch_30: {'Loss_train': 0.09338070501883824, 'Loss_val': 0.11994832009077072, 'Accuracy': 0.9666666388511658}\n",
      "epoch_31: {'Loss_train': 0.09095807477003998, 'Loss_val': 0.11877445876598358, 'Accuracy': 0.9666666388511658}\n",
      "epoch_32: {'Loss_train': 0.08915883497231536, 'Loss_val': 0.11631395667791367, 'Accuracy': 0.9666666388511658}\n",
      "epoch_33: {'Loss_train': 0.08650917717152172, 'Loss_val': 0.11759286373853683, 'Accuracy': 0.9638888835906982}\n",
      "epoch_34: {'Loss_train': 0.08520638383924961, 'Loss_val': 0.11445748805999756, 'Accuracy': 0.9666666388511658}\n",
      "epoch_35: {'Loss_train': 0.0828109189040131, 'Loss_val': 0.11329131573438644, 'Accuracy': 0.9694444537162781}\n",
      "epoch_36: {'Loss_train': 0.08141707962171899, 'Loss_val': 0.11184729635715485, 'Accuracy': 0.9694444537162781}\n",
      "epoch_37: {'Loss_train': 0.07845559960438145, 'Loss_val': 0.11336610466241837, 'Accuracy': 0.9638888835906982}\n",
      "epoch_38: {'Loss_train': 0.07722935701409976, 'Loss_val': 0.11097370833158493, 'Accuracy': 0.9722222089767456}\n",
      "epoch_39: {'Loss_train': 0.07526888545188638, 'Loss_val': 0.1092943623661995, 'Accuracy': 0.9694444537162781}\n",
      "epoch_40: {'Loss_train': 0.07474883103536235, 'Loss_val': 0.10970233380794525, 'Accuracy': 0.9666666388511658}\n",
      "epoch_41: {'Loss_train': 0.07239198059671455, 'Loss_val': 0.11012114584445953, 'Accuracy': 0.9611111283302307}\n",
      "epoch_42: {'Loss_train': 0.07108100694086816, 'Loss_val': 0.108155757188797, 'Accuracy': 0.9694444537162781}\n",
      "epoch_43: {'Loss_train': 0.06936214272346762, 'Loss_val': 0.10686046630144119, 'Accuracy': 0.9638888835906982}\n",
      "epoch_44: {'Loss_train': 0.06802800881365935, 'Loss_val': 0.10632222145795822, 'Accuracy': 0.9666666388511658}\n",
      "epoch_45: {'Loss_train': 0.06660429186498125, 'Loss_val': 0.10789044946432114, 'Accuracy': 0.9611111283302307}\n",
      "epoch_46: {'Loss_train': 0.06525286373992761, 'Loss_val': 0.1088358536362648, 'Accuracy': 0.9583333134651184}\n",
      "epoch_47: {'Loss_train': 0.06453884484039413, 'Loss_val': 0.10510271787643433, 'Accuracy': 0.9666666388511658}\n",
      "epoch_48: {'Loss_train': 0.06331746100137631, 'Loss_val': 0.10578050464391708, 'Accuracy': 0.9638888835906982}\n",
      "epoch_49: {'Loss_train': 0.061740917733146085, 'Loss_val': 0.10386555641889572, 'Accuracy': 0.9638888835906982}\n",
      "epoch_50: {'Loss_train': 0.06060049380693171, 'Loss_val': 0.10428816825151443, 'Accuracy': 0.9638888835906982}\n",
      "epoch_51: {'Loss_train': 0.05926323189503617, 'Loss_val': 0.10398653149604797, 'Accuracy': 0.9666666388511658}\n",
      "epoch_52: {'Loss_train': 0.058257355354726315, 'Loss_val': 0.10552947968244553, 'Accuracy': 0.9611111283302307}\n",
      "epoch_53: {'Loss_train': 0.0575734389324983, 'Loss_val': 0.10233849287033081, 'Accuracy': 0.9666666388511658}\n",
      "epoch_54: {'Loss_train': 0.05651406774090396, 'Loss_val': 0.10198410600423813, 'Accuracy': 0.9666666388511658}\n",
      "epoch_55: {'Loss_train': 0.054720408841967584, 'Loss_val': 0.10194484144449234, 'Accuracy': 0.9666666388511658}\n",
      "epoch_56: {'Loss_train': 0.05398089540087515, 'Loss_val': 0.10148122906684875, 'Accuracy': 0.9694444537162781}\n",
      "epoch_57: {'Loss_train': 0.053170709353354245, 'Loss_val': 0.10198194533586502, 'Accuracy': 0.9666666388511658}\n",
      "epoch_58: {'Loss_train': 0.05255555905815628, 'Loss_val': 0.1009591668844223, 'Accuracy': 0.9638888835906982}\n",
      "epoch_59: {'Loss_train': 0.05136107800321447, 'Loss_val': 0.10035165399312973, 'Accuracy': 0.9666666388511658}\n",
      "epoch_60: {'Loss_train': 0.050989783741533755, 'Loss_val': 0.10079748183488846, 'Accuracy': 0.9666666388511658}\n",
      "epoch_61: {'Loss_train': 0.049974742200639514, 'Loss_val': 0.10014127194881439, 'Accuracy': 0.9666666388511658}\n",
      "epoch_62: {'Loss_train': 0.049352162952224415, 'Loss_val': 0.10059766471385956, 'Accuracy': 0.9638888835906982}\n",
      "epoch_63: {'Loss_train': 0.048025142525633176, 'Loss_val': 0.0995558425784111, 'Accuracy': 0.9666666388511658}\n",
      "epoch_64: {'Loss_train': 0.04766063083791071, 'Loss_val': 0.0994214192032814, 'Accuracy': 0.9666666388511658}\n",
      "epoch_65: {'Loss_train': 0.04673738619312644, 'Loss_val': 0.09986667335033417, 'Accuracy': 0.9666666388511658}\n",
      "epoch_66: {'Loss_train': 0.04605918429378006, 'Loss_val': 0.0988546684384346, 'Accuracy': 0.9666666388511658}\n",
      "epoch_67: {'Loss_train': 0.044872135751777224, 'Loss_val': 0.098312146961689, 'Accuracy': 0.9666666388511658}\n",
      "epoch_68: {'Loss_train': 0.04445643340133958, 'Loss_val': 0.098353311419487, 'Accuracy': 0.9694444537162781}\n",
      "epoch_69: {'Loss_train': 0.04374945407940282, 'Loss_val': 0.0998779907822609, 'Accuracy': 0.9638888835906982}\n",
      "epoch_70: {'Loss_train': 0.04315375978541043, 'Loss_val': 0.09835391491651535, 'Accuracy': 0.9666666388511658}\n",
      "epoch_71: {'Loss_train': 0.04247853211644623, 'Loss_val': 0.09826482087373734, 'Accuracy': 0.9694444537162781}\n",
      "epoch_72: {'Loss_train': 0.0417538026554717, 'Loss_val': 0.09849970787763596, 'Accuracy': 0.9666666388511658}\n",
      "epoch_73: {'Loss_train': 0.04121003980851835, 'Loss_val': 0.09832605719566345, 'Accuracy': 0.9638888835906982}\n",
      "epoch_74: {'Loss_train': 0.040797134116292, 'Loss_val': 0.0972270742058754, 'Accuracy': 0.9694444537162781}\n",
      "epoch_75: {'Loss_train': 0.03980624610558152, 'Loss_val': 0.09791236370801926, 'Accuracy': 0.9694444537162781}\n",
      "epoch_76: {'Loss_train': 0.039240837925010257, 'Loss_val': 0.09740784764289856, 'Accuracy': 0.9666666388511658}\n",
      "epoch_77: {'Loss_train': 0.03893270049658087, 'Loss_val': 0.09794890135526657, 'Accuracy': 0.9666666388511658}\n",
      "epoch_78: {'Loss_train': 0.038377165090706614, 'Loss_val': 0.09743168950080872, 'Accuracy': 0.9666666388511658}\n",
      "epoch_79: {'Loss_train': 0.0377844469414817, 'Loss_val': 0.09777899831533432, 'Accuracy': 0.9694444537162781}\n",
      "epoch_80: {'Loss_train': 0.03685568544185824, 'Loss_val': 0.09679294377565384, 'Accuracy': 0.9666666388511658}\n",
      "epoch_81: {'Loss_train': 0.036900581750604844, 'Loss_val': 0.09760364890098572, 'Accuracy': 0.9666666388511658}\n",
      "epoch_82: {'Loss_train': 0.035678947592775026, 'Loss_val': 0.09865295886993408, 'Accuracy': 0.9638888835906982}\n",
      "epoch_83: {'Loss_train': 0.03580494643085533, 'Loss_val': 0.09660129249095917, 'Accuracy': 0.9694444537162781}\n",
      "epoch_84: {'Loss_train': 0.035110986419022085, 'Loss_val': 0.0964754968881607, 'Accuracy': 0.9666666388511658}\n",
      "epoch_85: {'Loss_train': 0.03450106318212218, 'Loss_val': 0.09777521342039108, 'Accuracy': 0.9638888835906982}\n",
      "epoch_86: {'Loss_train': 0.033794625393218466, 'Loss_val': 0.09711951017379761, 'Accuracy': 0.9666666388511658}\n",
      "epoch_87: {'Loss_train': 0.033690469660278825, 'Loss_val': 0.09781496226787567, 'Accuracy': 0.9666666388511658}\n",
      "epoch_88: {'Loss_train': 0.03346192924719718, 'Loss_val': 0.09643629938364029, 'Accuracy': 0.9694444537162781}\n",
      "epoch_89: {'Loss_train': 0.03284083737267388, 'Loss_val': 0.09641873836517334, 'Accuracy': 0.9694444537162781}\n",
      "epoch_90: {'Loss_train': 0.03237660974264145, 'Loss_val': 0.09658119082450867, 'Accuracy': 0.9666666388511658}\n",
      "epoch_91: {'Loss_train': 0.03172140436040031, 'Loss_val': 0.09676247835159302, 'Accuracy': 0.9666666388511658}\n",
      "epoch_92: {'Loss_train': 0.03137396950688627, 'Loss_val': 0.09766438603401184, 'Accuracy': 0.9694444537162781}\n",
      "epoch_93: {'Loss_train': 0.031089479631433884, 'Loss_val': 0.09714558720588684, 'Accuracy': 0.9694444537162781}\n",
      "epoch_94: {'Loss_train': 0.03071039950268136, 'Loss_val': 0.09823743999004364, 'Accuracy': 0.9694444537162781}\n",
      "epoch_95: {'Loss_train': 0.030464658254964486, 'Loss_val': 0.09665893018245697, 'Accuracy': 0.9722222089767456}\n",
      "epoch_96: {'Loss_train': 0.02965340334922075, 'Loss_val': 0.09661335498094559, 'Accuracy': 0.9722222089767456}\n",
      "epoch_97: {'Loss_train': 0.029628903170426688, 'Loss_val': 0.09695027768611908, 'Accuracy': 0.9722222089767456}\n",
      "epoch_98: {'Loss_train': 0.029150831140577795, 'Loss_val': 0.09682481735944748, 'Accuracy': 0.9694444537162781}\n",
      "epoch_99: {'Loss_train': 0.028833379099766413, 'Loss_val': 0.09738753736019135, 'Accuracy': 0.9666666388511658}\n"
     ]
    }
   ],
   "source": [
    "# バッチサイズとバッチの個数を定義\n",
    "batch_size = 32\n",
    "num_batches = X_train.shape[0] // batch_size + 1\n",
    "learning_rate = 0.03\n",
    "\n",
    "# 学習・検証結果格納用辞書\n",
    "train_results = {}\n",
    "\n",
    "for i, _ in enumerate(range(100)):\n",
    "    #　インデックスをシャッフル\n",
    "    shuffled_indices = np.random.permutation(len(y_train))\n",
    "\n",
    "    # shuffled_indicesからの取り出し範囲初期化\n",
    "    idx_start = 0\n",
    "    idx_end = batch_size\n",
    "\n",
    "    # 各バッチでの学習データに対するlossを累積する用の変数\n",
    "    cum_loss = 0\n",
    "\n",
    "    for _ in range(num_batches):\n",
    "        # 学習データ定義\n",
    "        indices_train = shuffled_indices[ idx_start:idx_end ]\n",
    "        X_train_batch = X_train[indices_train]\n",
    "        y_train_batch = y_train[indices_train]\n",
    "\n",
    "        # 順伝播の計算。F.cross_entropyの中でsoftmaxが適用されるので適用不要\n",
    "        #y_pred = F.softmax(MLP_model(X_train_batch), dim=1)\n",
    "        y_pred = MLP_model(X_train_batch)\n",
    "\n",
    "        # 損失計算\n",
    "        loss = F.cross_entropy(y_pred , y_train_batch)\n",
    "        cum_loss += loss.item()\n",
    "        # 逆伝播の計算\n",
    "        loss.backward()\n",
    "\n",
    "        # パラメタ更新\n",
    "        # with torch.no_grad():\n",
    "        #     for params in MLP_model.parameters():\n",
    "        #         params -= learning_rate * params.grad\n",
    "        # 実装したOptimizerクラスを用いてパラメタ更新\n",
    "        optim_torch.step()\n",
    "\n",
    "        # 勾配初期化。nn.Moduleから継承しているので.zero_gradはそのまま使える。\n",
    "        # MLP_model.zero_grad()\n",
    "        optim_torch.zero_grad()\n",
    "\n",
    "        # 取り出し範囲更新\n",
    "        idx_start += batch_size\n",
    "        idx_end += batch_size\n",
    "    \n",
    "    # 検証データに対する損失を計算\n",
    "    y_pred_val = MLP_model(X_val)\n",
    "    loss_val = F.cross_entropy(y_pred_val, y_val)\n",
    "\n",
    "    # 損失、accuracyを記録\n",
    "    train_results[f\"epoch_{i}\"] = {\n",
    "        \"Loss_train\": cum_loss / num_batches,\n",
    "        \"Loss_val\": loss_val.item(),\n",
    "        \"Accuracy\": ( (torch.argmax(y_pred_val, dim=1) == y_val).sum() / len(y_val) ).item()\n",
    "    }\n",
    "\n",
    "    print(f'epoch_{i}: {train_results[f\"epoch_{i}\"]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
