{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深層学習ノートブック-3 pytorchによる多項ロジスティック回帰\n",
    "参考：  \n",
    "* [行列積](https://w3e.kanazawa-it.ac.jp/math/category/gyouretu/senkeidaisu/henkan-tex.cgi?target=/math/category/gyouretu/senkeidaisu/gyouretu-no-seki.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorchのAutograd, Tensorを用いて多項ロジスティック回帰による分類をスクラッチで実装する。  \n",
    "ここで実装する一連の流れは深層学習における学習プロセスの基礎であり、非常に重要。  \n",
    "\n",
    "ここではMNIST（手書き数字(0~9)）データセットを用いた10クラス分類のタスクを多項ロジスティック回帰で解くことを考える。  \n",
    "MNISTデータセットにある各pixel値(8x8=64)を特徴量として扱う。  \n",
    "\n",
    "データ数をm、特徴量の行列を$\\bm{X}$、$\\bm{X}$に対応する重み行列を$W^T$※とすると、  \n",
    "softmax関数への入力$\\bm{z}$は下記のように表せる。  \n",
    "※行列積の形で表わすために転置をとっている。\n",
    "\n",
    "\n",
    "$\\bm{z} = \\bm{XW}^T+\\bm{b} $  \n",
    "$=\\left(\n",
    "\\begin{matrix} \n",
    "x_{1,1} & x_{1,2} & ... & x_{1,64}\\\\ \n",
    "x_{2,1} & x_{2,2} & ... & x_{2, 64}\\\\\n",
    ". & . & ... & .\\\\\n",
    "x_{m,1} & x_{m,2} & ... & x_{m, 64}\n",
    "\\end{matrix} \n",
    "\\right)$\n",
    "$\\left(\n",
    "\\begin{matrix} \n",
    "w_{1,1} & w_{1,2} & ... & w_{1,10}\\\\ \n",
    "w_{2,1} & w_{2,2} & ... & x_{2,10}\\\\\n",
    ". & . & ... & .\\\\\n",
    "w_{64,1} & x_{64,2} & ... & x_{64, 10}\n",
    "\\end{matrix} \n",
    "\\right)$\n",
    "$+\\left(\n",
    "\\begin{matrix} \n",
    "b_{1} & b_{2} & ... & b_{10}\\\\ \n",
    "b_{1} & b_{2} & ... & b_{10}\\\\\n",
    ". & . & ... & .\\\\\n",
    "b_{1} & b_{2} & ... & b_{10}\n",
    "\\end{matrix}\n",
    "\\right)$  \n",
    "\n",
    "$=\\left(\n",
    "\\begin{matrix} \n",
    "\\sum_{k=1}^{64} x_{1, k}w_{k, 1}+b_1 & \\sum_{k=1}^{64} x_{1, k}w_{k, 2}+b_2 & ... & \\sum_{k=1}^{64} x_{1, k}w_{k, 10}+b_{10}\\\\ \n",
    "\\sum_{k=1}^{64} x_{2, k}w_{k, 1}+b_1 & \\sum_{k=1}^{64} x_{2, k}w_{k, 2}+b_2 & ... & \\sum_{k=1}^{64} x_{2, k}w_{k, 10}+b_{10}\\\\ \n",
    ". & . & ... & .\\\\\n",
    "\\sum_{k=1}^{64} x_{m, k}w_{k, 1}+b_1 & \\sum_{k=1}^{64} x_{m, k}w_{k, 2}+b_2 & ... & \\sum_{k=1}^{64} x_{m, k}w_{k, 10}+b_{10}\\\\ \n",
    "\\end{matrix} \n",
    "\\right)$\n",
    "\n",
    "$=\\left(\n",
    "\\begin{matrix} \n",
    "z_{1,1} & z_{1,2} & ... & z_{1,10}\\\\ \n",
    "z_{2,1} & z_{2,2} & ... & z_{2,10}\\\\\n",
    ". & . & ... & .\\\\\n",
    "z_{m,1} & z_{m,2} & ... & z_{m, 10}\n",
    "\\end{matrix} \n",
    "\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bm{X}$のshapeはデータ数m × 特徴量数64  \n",
    "$\\bm{W}^T$は重みづけの対象数（すなわち特徴量数64）× 最終的な出力列数（10クラス分類なので10）、  \n",
    "$\\bm{b}$は1 × 最終的な出力列数となるが、上記ではbroadcastされた状態で書いている。  \n",
    "最終的に$\\bm{z}$は各データ数 × クラス数というshapeで表わされ、クラスごとに線形回帰の結果が対応する。  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
