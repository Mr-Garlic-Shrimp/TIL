{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深層学習ノートブック-1 Tensorの取り扱い基礎\n",
    "Tensorはテンサーが正式な読み方ぽい。  \n",
    "テンサーは学部の頃に勉強した気がしたが忘れたので、ひとまずは多次元配列のことと理解しておく。  \n",
    "PytorchにおけるTensorも多次元配列のようなイメージであり、以下の特徴を持つ。  \n",
    "* 深層学習の計算の核となるデータ構造\n",
    "* Numpy Arrayと非常によく似ている\n",
    "* GPUによる計算の高速化が可能\n",
    "* 自動微分(Auto Grad)が可能\n",
    "\n",
    "参考:  \n",
    "https://remedics.air-nifty.com/academy/2020/02/post-fbe026.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb0a5cb5270>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torchでpytorchをimport\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# torchで使う疑似乱数のseedは設定\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ・Tensorの作成\n",
    "torch.tensor()にlistを入れることでtensorを作成出来る。  \n",
    "デフォルトの要素のデータ型はfloat32である。（numpyはfloat64がデフォルトなので注意）  \n",
    "深層学習では扱うデータ量が多いので、データ型を意識してなるべく省メモリで作ることが重要。  \n",
    "torch.tensor()のdtype引数を使ってデータ型を指定可能。（例:dtype=torch.float64）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = [1, 2, 3, 4]\n",
    "tensor_from_list = torch.tensor(my_list)\n",
    "tensor_from_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tensor_from_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intを入れて作成すると、データ型はtorch.int64になる\n",
    "tensor_from_list.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = [1., 2., 3., 4.]\n",
    "tensor_from_list = torch.tensor(my_list)\n",
    "tensor_from_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_list.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtypeを指定することで別の型で作成可能\n",
    "tensor_from_list = torch.tensor(my_list, dtype=torch.float64)\n",
    "tensor_from_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorのshapeを表示\n",
    "tensor_from_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ・Tensor生成関数\n",
    "numpyのように基本的な配列を生成できる関数がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 x 3で要素が全て０のテンサー作成\n",
    "zeros_tensor = torch.zeros((2, 3))\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 x 3で要素が全て1のテンサー作成\n",
    "ones_tensor = torch.ones((2, 3))\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 x 4で単位行列作成\n",
    "ones_tensor = torch.eye(4)\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150],\n",
       "        [0.3829, 0.9593],\n",
       "        [0.3904, 0.6009],\n",
       "        [0.2566, 0.7936]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 x 2で要素がランダムのテンサー作成\n",
    "rand_tensor = torch.rand(4, 2)\n",
    "rand_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ・Tensorのshapeを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ・Tensorの操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x3x4の3次元配列を作成。torchはタプルでそのまま入れることに注意\n",
    "tensor_example = torch.rand((2, 3, 4))\n",
    "np_example = np.random.rand(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1053, 0.2695, 0.3588, 0.1994],\n",
       "         [0.5472, 0.0062, 0.9516, 0.0753],\n",
       "         [0.8860, 0.5832, 0.3376, 0.8090]],\n",
       "\n",
       "        [[0.5779, 0.9040, 0.5547, 0.3423],\n",
       "         [0.6343, 0.3644, 0.7104, 0.9464],\n",
       "         [0.7890, 0.2814, 0.7886, 0.5895]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_example.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※復習：  \n",
    "多次元配列のshapeの各インデックスをRankと呼ぶのであった。  \n",
    "上記ではRank=0は2、Rank=1は3、Rank=2は4。N次元配列のshapeは左からイメージしていくとわかりやすい。  \n",
    "上記の3次元配列の場合は、奥行き2、縦3、横4という形状の配列である。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1053, 0.2695, 0.3588, 0.1994],\n",
       "         [0.5779, 0.9040, 0.5547, 0.3423]],\n",
       "\n",
       "        [[0.5472, 0.0062, 0.9516, 0.0753],\n",
       "         [0.6343, 0.3644, 0.7104, 0.9464]],\n",
       "\n",
       "        [[0.8860, 0.5832, 0.3376, 0.8090],\n",
       "         [0.7890, 0.2814, 0.7886, 0.5895]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 転置。引数の配列のRankをどう並び替えるか指定する。\n",
    "permuted_tensor = torch.permute(tensor_example, (1, 0, 2) )\n",
    "permuted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元のtensorからshapeが入れ替わっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1053, 0.2695, 0.3588, 0.1994],\n",
       "         [0.5779, 0.9040, 0.5547, 0.3423]],\n",
       "\n",
       "        [[0.5472, 0.0062, 0.9516, 0.0753],\n",
       "         [0.6343, 0.3644, 0.7104, 0.9464]],\n",
       "\n",
       "        [[0.8860, 0.5832, 0.3376, 0.8090],\n",
       "         [0.7890, 0.2814, 0.7886, 0.5895]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpyの場合、上記のtransposeに相当する。\n",
    "# 一方、pytorchのtransposeは2軸を入れ変える操作なので混同しないように注意。\n",
    "# 使い方としては対象のtensor, 入れ替え対象のRankその1, 入れ替え対象のRankその2という感じ。\n",
    "torch.transpose(tensor_example, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の場合、Rank=0とRank=1を入れ替える操作となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1053, 0.2695, 0.3588, 0.1994],\n",
      "        [0.5472, 0.0062, 0.9516, 0.0753],\n",
      "        [0.8860, 0.5832, 0.3376, 0.8090],\n",
      "        [0.5779, 0.9040, 0.5547, 0.3423],\n",
      "        [0.6343, 0.3644, 0.7104, 0.9464],\n",
      "        [0.7890, 0.2814, 0.7886, 0.5895]])\n"
     ]
    }
   ],
   "source": [
    "# reshape.3 x 2 x 4だったtensorを6 x 4にreshapeする\n",
    "reshaped_tensor = torch.reshape(tensor_example, (6, 4) )\n",
    "print(reshaped_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5472, 0.0062, 0.9516, 0.0753],\n",
       "        [0.8860, 0.5832, 0.3376, 0.8090],\n",
       "        [0.5779, 0.9040, 0.5547, 0.3423],\n",
       "        [0.6343, 0.3644, 0.7104, 0.9464],\n",
       "        [0.7890, 0.2814, 0.7886, 0.5895]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor[0] = 0\n",
    "reshaped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5472, 0.0062, 0.9516, 0.0753],\n",
       "         [0.8860, 0.5832, 0.3376, 0.8090]],\n",
       "\n",
       "        [[0.5779, 0.9040, 0.5547, 0.3423],\n",
       "         [0.6343, 0.3644, 0.7104, 0.9464],\n",
       "         [0.7890, 0.2814, 0.7886, 0.5895]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ！注意\n",
    "torch.reshapeの結果はreshape前のtensor_exapmleと同じメモリを参照しているため、  \n",
    "reshaped_tensroに何か操作を施すと、元のtensor_exampleも変更されてしまうことに注意。  \n",
    "これはtorch側でメモリを節約するための工夫である。  \n",
    "ただし、tensor_exampleがメモリ上に連続的に格納されていない場合は、参照ではなくコピーを返す。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例\n",
    "x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "# rank2なら.Tで転置可能\n",
    "y = x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# メモリに連続的に保存されているか確認する\n",
    "y.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor.reshape()という書き方もできる\n",
    "z = y.reshape((1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0] = 0\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 5],\n",
       "        [2, 4, 6]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape元は変更されていない。\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のようにreshape元がメモリに連続的に保存されてい無ければ、  \n",
    "reshape結果はコピーとなる。  \n",
    "メモリ節約のために参照かコピーかを厳密に気にしながらreshapeする必要がある場合は.viewを使用するとよい。  \n",
    ".viewはメモリに連続的に保存されている場合のみ（参照可能な場合のみ）shapeが変更される。不連続の場合はエラーとなる。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/work/TIL/Machine_Learning/Deep_Learning/DL_notebook-1_Tensor.ipynb Cell 39\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6a7570797465726c61625f636f6e7461696e65725f6a7570797465725f31222c22637764223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74752d32322e30345c5c227d/work/TIL/Machine_Learning/Deep_Learning/DL_notebook-1_Tensor.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# yは不連続なメモリに保存されているのでエラーになる\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6a7570797465726c61625f636f6e7461696e65725f6a7570797465725f31222c22637764223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74752d32322e30345c5c227d/work/TIL/Machine_Learning/Deep_Learning/DL_notebook-1_Tensor.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m y\u001b[39m.\u001b[39;49mview((\u001b[39m1\u001b[39;49m, \u001b[39m6\u001b[39;49m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "# yは不連続なメモリに保存されているのでエラーになる\n",
    "y.view((1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xは連続的なので変形可能\n",
    "print(x.is_contiguous())\n",
    "x.view((1, 6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
