{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深層学習ノートブック-1 Tensorの取り扱い基礎\n",
    "Tensorはテンサーが正式な読み方ぽい。  \n",
    "テンサーは学部の頃に勉強したが忘れたので、ひとまずは多次元配列のことと理解しておく。  \n",
    "PytorchにおけるTensorも多次元配列のようなイメージであり、以下の特徴を持つ。  \n",
    "* 深層学習の計算の核となるデータ構造\n",
    "* Numpy Arrayと非常によく似ている\n",
    "* GPUによる計算の高速化が可能\n",
    "* 自動微分(Auto Grad)が可能\n",
    "\n",
    "参考:  \n",
    "https://remedics.air-nifty.com/academy/2020/02/post-fbe026.html  \n",
    "https://manabitimes.jp/math/1845  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb47ff9ed30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torchでpytorchをimport\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# torchで使う疑似乱数のseedは設定\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ・Tensorの作成\n",
    "torch.tensor()にlistを入れることでtensorを作成出来る。  \n",
    "デフォルトの要素のデータ型はfloat32である。（numpyはfloat64がデフォルトなので注意）  \n",
    "深層学習では扱うデータ量が多いので、データ型を意識してなるべく省メモリで作ることが重要。  \n",
    "torch.tensor()のdtype引数を使ってデータ型を指定可能。（例:dtype=torch.float64）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = [1, 2, 3, 4]\n",
    "tensor_from_list = torch.tensor(my_list)\n",
    "tensor_from_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tensor_from_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intを入れて作成すると、データ型はtorch.int64になる\n",
    "tensor_from_list.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = [1., 2., 3., 4.]\n",
    "tensor_from_list = torch.tensor(my_list)\n",
    "tensor_from_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_list.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtypeを指定することで別の型で作成可能\n",
    "tensor_from_list = torch.tensor(my_list, dtype=torch.float64)\n",
    "tensor_from_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorのshapeを表示\n",
    "tensor_from_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ・Tensor生成関数\n",
    "numpyのように基本的な配列を生成できる関数がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 x 3で要素が全て０のテンサー作成\n",
    "zeros_tensor = torch.zeros((2, 3))\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 x 3で要素が全て1のテンサー作成\n",
    "ones_tensor = torch.ones((2, 3))\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 x 4で単位行列作成\n",
    "ones_tensor = torch.eye(4)\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150],\n",
       "        [0.3829, 0.9593],\n",
       "        [0.3904, 0.6009],\n",
       "        [0.2566, 0.7936]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 x 2で要素がランダムのテンサー作成\n",
    "rand_tensor = torch.rand(4, 2)\n",
    "rand_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ・Tensorのshapeを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ・Tensorの操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x3x4の3次元配列を作成。torchはタプルでそのまま入れることに注意\n",
    "tensor_example = torch.rand((2, 3, 4))\n",
    "np_example = np.random.rand(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1053, 0.2695, 0.3588, 0.1994],\n",
       "         [0.5472, 0.0062, 0.9516, 0.0753],\n",
       "         [0.8860, 0.5832, 0.3376, 0.8090]],\n",
       "\n",
       "        [[0.5779, 0.9040, 0.5547, 0.3423],\n",
       "         [0.6343, 0.3644, 0.7104, 0.9464],\n",
       "         [0.7890, 0.2814, 0.7886, 0.5895]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_example.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※復習：  \n",
    "多次元配列のshapeの各インデックスをRankと呼ぶのであった。  \n",
    "上記ではRank=0は2、Rank=1は3、Rank=2は4。N次元配列のshapeは左からイメージしていくとわかりやすい。  \n",
    "上記の3次元配列の場合は、奥行き2、縦3、横4という形状の配列である。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - permute\n",
    "Rankを入れ替える操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1053, 0.2695, 0.3588, 0.1994],\n",
       "         [0.5779, 0.9040, 0.5547, 0.3423]],\n",
       "\n",
       "        [[0.5472, 0.0062, 0.9516, 0.0753],\n",
       "         [0.6343, 0.3644, 0.7104, 0.9464]],\n",
       "\n",
       "        [[0.8860, 0.5832, 0.3376, 0.8090],\n",
       "         [0.7890, 0.2814, 0.7886, 0.5895]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 転置。引数の配列のRankをどう並び替えるか指定する。\n",
    "permuted_tensor = torch.permute(tensor_example, (1, 0, 2) )\n",
    "permuted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元のtensorからshapeが入れ替わっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1053, 0.2695, 0.3588, 0.1994],\n",
       "         [0.5779, 0.9040, 0.5547, 0.3423]],\n",
       "\n",
       "        [[0.5472, 0.0062, 0.9516, 0.0753],\n",
       "         [0.6343, 0.3644, 0.7104, 0.9464]],\n",
       "\n",
       "        [[0.8860, 0.5832, 0.3376, 0.8090],\n",
       "         [0.7890, 0.2814, 0.7886, 0.5895]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpyの場合、上記のtransposeに相当する。\n",
    "# 一方、pytorchのtransposeは2軸を入れ変える操作なので混同しないように注意。\n",
    "# 使い方としては対象のtensor, 入れ替え対象のRankその1, 入れ替え対象のRankその2という感じ。\n",
    "torch.transpose(tensor_example, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の場合、Rank=0とRank=1を入れ替える操作となる。  \n",
    "入れ替えではなく最大のRank数もいじる場合はreshapeを用いる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1053, 0.2695, 0.3588, 0.1994],\n",
      "        [0.5472, 0.0062, 0.9516, 0.0753],\n",
      "        [0.8860, 0.5832, 0.3376, 0.8090],\n",
      "        [0.5779, 0.9040, 0.5547, 0.3423],\n",
      "        [0.6343, 0.3644, 0.7104, 0.9464],\n",
      "        [0.7890, 0.2814, 0.7886, 0.5895]])\n"
     ]
    }
   ],
   "source": [
    "# reshape.3 x 2 x 4だったtensorを6 x 4にreshapeする\n",
    "reshaped_tensor = torch.reshape(tensor_example, (6, 4) )\n",
    "print(reshaped_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5472, 0.0062, 0.9516, 0.0753],\n",
       "        [0.8860, 0.5832, 0.3376, 0.8090],\n",
       "        [0.5779, 0.9040, 0.5547, 0.3423],\n",
       "        [0.6343, 0.3644, 0.7104, 0.9464],\n",
       "        [0.7890, 0.2814, 0.7886, 0.5895]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor[0] = 0\n",
    "reshaped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5472, 0.0062, 0.9516, 0.0753],\n",
       "         [0.8860, 0.5832, 0.3376, 0.8090]],\n",
       "\n",
       "        [[0.5779, 0.9040, 0.5547, 0.3423],\n",
       "         [0.6343, 0.3644, 0.7104, 0.9464],\n",
       "         [0.7890, 0.2814, 0.7886, 0.5895]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ！注意\n",
    "torch.reshapeの結果はreshape前のtensor_exapmleと同じメモリを参照しているため、  \n",
    "reshaped_tensorに何か操作を施すと、元のtensor_exampleも変更されてしまうことに注意。  \n",
    "これはtorch側でメモリを節約するための工夫である。  \n",
    "ただし、tensor_exampleがメモリ上に連続的に格納されていない場合は、参照ではなくコピーを返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例\n",
    "x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "# rank2なら.Tで転置可能\n",
    "y = x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# メモリに連続的に保存されているか確認する\n",
    "y.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor.reshape()という書き方もできる\n",
    "z = y.reshape((1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0] = 0\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 5],\n",
       "        [2, 4, 6]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape元は変更されていない。\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のようにreshape元がメモリに連続的に保存されてい無ければ、  \n",
    "reshape結果はコピーとなる。  \n",
    "メモリ節約のために参照かコピーかを厳密に気にしながらreshapeする必要がある場合は.viewを使用するとよい。  \n",
    ".viewはメモリに連続的に保存されている場合のみ（参照可能な場合のみ）shapeが変更される。不連続の場合はエラーとなる。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/work/TIL/Machine_Learning/Deep_Learning/DL_notebook-1_Tensor.ipynb Cell 39\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6a7570797465726c61625f636f6e7461696e65725f6a7570797465725f31222c22637764223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74752d32322e30345c5c227d/work/TIL/Machine_Learning/Deep_Learning/DL_notebook-1_Tensor.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# yは不連続なメモリに保存されているのでエラーになる\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6a7570797465726c61625f636f6e7461696e65725f6a7570797465725f31222c22637764223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74752d32322e30345c5c227d/work/TIL/Machine_Learning/Deep_Learning/DL_notebook-1_Tensor.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m y\u001b[39m.\u001b[39;49mview((\u001b[39m1\u001b[39;49m, \u001b[39m6\u001b[39;49m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "# yは不連続なメモリに保存されているのでエラーになる\n",
    "y.view((1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xは連続的なので変形可能\n",
    "print(x.is_contiguous())\n",
    "x.view((1, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - flatten\n",
    "tensorを１次元（Rank0）にする操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.5472, 0.0062, 0.9516, 0.0753, 0.8860,\n",
      "        0.5832, 0.3376, 0.8090, 0.5779, 0.9040, 0.5547, 0.3423, 0.6343, 0.3644,\n",
      "        0.7104, 0.9464, 0.7890, 0.2814, 0.7886, 0.5895])\n",
      "torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "# reshape.3 x 2 x 4だったtensorを6 x 4にreshapeする\n",
    "flattend_tensor = torch.flatten(tensor_example)\n",
    "print(flattend_tensor)\n",
    "print(flattend_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 元々の形状\n",
    "print(tensor_example.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - flatten\n",
    "tensorを１次元（Rank0）にする操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.5472, 0.0062, 0.9516, 0.0753, 0.8860,\n",
      "        0.5832, 0.3376, 0.8090, 0.5779, 0.9040, 0.5547, 0.3423, 0.6343, 0.3644,\n",
      "        0.7104, 0.9464, 0.7890, 0.2814, 0.7886, 0.5895])\n",
      "torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "flattend_tensor = torch.flatten(tensor_example)\n",
    "print(flattend_tensor)\n",
    "print(flattend_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - squeeze\n",
    "余分な次元を削除する操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor_example = torch.tensor([[[1], [2], [3]]])\n",
    "print(tensor_example.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のRank=0,2はあってもなくてもよく、Rank=1の1列だけあれば情報としては事足りる場合がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "squeezed_tensor =torch.squeeze(tensor_example)\n",
    "print(squeezed_tensor)\n",
    "print(squeezed_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の通り無くてもかまわないRank=0とRank=2が削除されてすっきりさせることが出来る。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - unsqueeze\n",
    "Rankを増やす操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1],\n",
      "          [2],\n",
      "          [3]]]])\n",
      "torch.Size([1, 1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# Rank=0の前に新たなRankを追加する。\n",
    "unsqueezed_tensor =torch.unsqueeze(tensor_example, 0)\n",
    "print(unsqueezed_tensor)\n",
    "print(unsqueezed_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のように任意の場所にRankを追加できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下記のようなの書き方でも追加可能。\n",
    "tensor_example[None, :, :, :].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ・Tensorの便利関数\n",
    "numpyと同様にsum,mean等がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5315, 0.1587, 0.6542],\n",
      "        [0.3278, 0.6532, 0.3958]])\n"
     ]
    }
   ],
   "source": [
    "tensor_example = torch.rand((2, 3))\n",
    "print(tensor_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7212)\n",
      "tensor(2.7212)\n"
     ]
    }
   ],
   "source": [
    "# 合計。どちらの書き方でもOK\n",
    "print(torch.sum(tensor_example))\n",
    "print(tensor_example.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7290, 0.3984, 0.8088],\n",
       "        [0.5725, 0.8082, 0.6291]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(tensor_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "戻り値はfloatではなく全てtensorであることに注意。  \n",
    "数字だけ取り出したいときは.item()を使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.72123384475708"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(tensor_example).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ・Tensorの演算\n",
    "numpy arrayと同様にTensorでも配列の要素ごとの四則演算、行列の積（内積）が計算できる。  \n",
    "\n",
    "■ 加減算および要素毎の乗除算  \n",
    "* Numpy Arrayと同様 (+, -, *, /)  \n",
    "\n",
    "■ 行列の積(内積)  →深層学習ではよく使う  \n",
    "* torch.mm()/torch.matmul() もしくは@演算子を使用  \n",
    "    ※mmやmatmulはMatrix Multiplyの略  \n",
    "* Numpy Arrayではnp.dot()または@演算子を使用  \n",
    "* torch.dot()は，1次元に対してのみドット積(ベクトルの内積)を計算  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 要素ごとの四則演算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2666, 0.6274, 0.2696],\n",
      "        [0.4414, 0.2969, 0.8317],\n",
      "        [0.1053, 0.2695, 0.3588]])\n",
      "tensor([[0.1994, 0.5472, 0.0062],\n",
      "        [0.9516, 0.0753, 0.8860],\n",
      "        [0.5832, 0.3376, 0.8090]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((3, 3))\n",
    "b = torch.rand((3, 3))\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4659, 1.1746, 0.2758],\n",
       "        [1.3929, 0.3722, 1.7177],\n",
       "        [0.6885, 0.6071, 1.1678]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0672,  0.0803,  0.2635],\n",
       "        [-0.5102,  0.2217, -0.0543],\n",
       "        [-0.4779, -0.0682, -0.4502]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 減法\n",
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0531, 0.3433, 0.0017],\n",
       "        [0.4200, 0.0223, 0.7369],\n",
       "        [0.0614, 0.0910, 0.2903]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 乗法\n",
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3372,  1.1467, 43.7683],\n",
       "        [ 0.4638,  3.9450,  0.9387],\n",
       "        [ 0.1806,  0.7982,  0.4435]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 除法\n",
    "a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Tensorの積\n",
    "tensorの積の計算は以下３通りある。@の書き方がよく用いられる。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8075, 0.2841, 0.7757],\n",
       "        [0.8556, 0.5447, 0.9386],\n",
       "        [0.4867, 0.1991, 0.5297]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a・bと同じ意味。順番注意。\n",
    "torch.mm(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8075, 0.2841, 0.7757],\n",
       "        [0.8556, 0.5447, 0.9386],\n",
       "        [0.4867, 0.1991, 0.5297]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8075, 0.2841, 0.7757],\n",
       "        [0.8556, 0.5447, 0.9386],\n",
       "        [0.4867, 0.1991, 0.5297]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# よく使う書き方\n",
    "a @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - ブロードキャスティング\n",
    "* Numpy同様，broad castingの機能がある  \n",
    "* 復習：演算する2つのtensorが同じ次元ではない場合，次元が少ない方が次元を増やすことで演算を可能にする仕組み  \n",
    "* 深層学習では頻出  \n",
    "* ブロードキャスティングのルール  \n",
    "    * rank数が異なる場合，少ない方の配列のshapeの左側にサイズ1の次元を追加する(例: (2, 3) -> (1, 2, 3))  \n",
    "    * shapeの右側から値(サイズ数)を比較し、数が一致するか、サイズが1であればブロードキャスティングが可能  \n",
    "    * サイズ1の次元を大きい方の次元のサイズへ拡大する。この際、値はコピーされる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of temp1 :torch.Size([3, 2])\n",
      "tensor([[33.3572, 57.8186],\n",
      "        [ 6.0039, 28.4563],\n",
      "        [20.0666, 50.1386]])\n",
      "-------------\n",
      "shape of temp2 :torch.Size([2])\n",
      "tensor([31.3948, 46.5352])\n"
     ]
    }
   ],
   "source": [
    "temp1 = torch.rand((3, 2)) * 100\n",
    "temp2 = torch.rand((2)) * 100\n",
    "print(f'shape of temp1 :{temp1.shape}')\n",
    "print(temp1)\n",
    "print('-------------')\n",
    "print(f'shape of temp2 :{temp2.shape}')\n",
    "print(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 64.7520, 104.3538],\n",
       "        [ 37.3988,  74.9916],\n",
       "        [ 51.4614,  96.6738]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1 + temp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp2がブロードキャスティングされてtemp1に足されていることが分かる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例2) (3,3)とスカラーの演算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0766, 5.8460, 5.3624],\n",
       "        [5.3083, 5.0850, 5.0029],\n",
       "        [5.6431, 5.3908, 5.6947]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3, 3)\n",
    "scalar = 5\n",
    "a + scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例3) (3, 3)と(1, 3)の演算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0897, 0.8712, 0.1330]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand(1, 3)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1663, 1.7172, 0.4954],\n",
       "        [0.3980, 0.9562, 0.1359],\n",
       "        [0.7327, 1.2620, 0.8276]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0766, 0.8460, 0.3624],\n",
       "        [0.3083, 0.0850, 0.0029],\n",
       "        [0.6431, 0.3908, 0.6947]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例4) (32, 128, 128, 3)と(128, 128, 3)の演算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((32, 128, 128, 3))\n",
    "b = torch.rand((128, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7710, 1.4229, 0.5530],\n",
       "          [1.0756, 0.8071, 1.6654],\n",
       "          [0.9835, 0.9913, 1.8300],\n",
       "          ...,\n",
       "          [0.6746, 1.1276, 1.1759],\n",
       "          [1.6491, 0.8438, 1.0421],\n",
       "          [1.0628, 1.0259, 0.5029]],\n",
       "\n",
       "         [[0.2446, 1.7456, 1.0428],\n",
       "          [1.2247, 0.6800, 1.6920],\n",
       "          [1.6483, 1.0392, 1.1523],\n",
       "          ...,\n",
       "          [1.3965, 1.1794, 0.9092],\n",
       "          [0.9807, 1.5331, 0.8732],\n",
       "          [0.7846, 1.0218, 0.9091]],\n",
       "\n",
       "         [[0.6367, 0.8302, 0.6155],\n",
       "          [1.2663, 1.3417, 0.6631],\n",
       "          [1.0617, 0.5932, 1.0978],\n",
       "          ...,\n",
       "          [1.0029, 1.3304, 1.4227],\n",
       "          [0.8284, 1.6720, 1.0244],\n",
       "          [1.4785, 0.6243, 1.0308]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.4339, 0.5114, 1.2578],\n",
       "          [1.1774, 1.1114, 0.3516],\n",
       "          [1.3588, 1.2006, 0.5233],\n",
       "          ...,\n",
       "          [1.0652, 0.2965, 0.7732],\n",
       "          [1.1293, 0.9161, 1.0054],\n",
       "          [1.3012, 1.3583, 1.0479]],\n",
       "\n",
       "         [[0.2182, 1.5599, 0.9472],\n",
       "          [1.1068, 1.1393, 1.3067],\n",
       "          [0.5322, 1.6161, 0.2641],\n",
       "          ...,\n",
       "          [1.4227, 0.4848, 1.7122],\n",
       "          [1.3707, 0.8542, 1.0773],\n",
       "          [1.2489, 1.4397, 1.0672]],\n",
       "\n",
       "         [[1.0395, 1.5744, 1.3543],\n",
       "          [1.1533, 1.2876, 1.6124],\n",
       "          [1.1595, 1.1013, 1.5711],\n",
       "          ...,\n",
       "          [0.4243, 1.9373, 1.4311],\n",
       "          [0.8654, 0.4763, 1.2844],\n",
       "          [1.2366, 1.0964, 0.3542]]],\n",
       "\n",
       "\n",
       "        [[[0.9306, 0.9516, 1.0754],\n",
       "          [1.0974, 0.6324, 1.8503],\n",
       "          [1.5987, 0.7808, 1.3043],\n",
       "          ...,\n",
       "          [0.9872, 0.7909, 0.7838],\n",
       "          [1.0273, 1.4619, 1.3008],\n",
       "          [0.9867, 1.2639, 1.2220]],\n",
       "\n",
       "         [[0.9005, 1.2819, 0.8595],\n",
       "          [1.3606, 0.1899, 1.0732],\n",
       "          [0.7355, 0.4957, 1.5646],\n",
       "          ...,\n",
       "          [1.1963, 1.5437, 0.7433],\n",
       "          [1.3805, 1.5004, 1.0169],\n",
       "          [0.6622, 1.2752, 0.4312]],\n",
       "\n",
       "         [[1.0899, 0.4186, 0.6898],\n",
       "          [0.8239, 1.1094, 0.8181],\n",
       "          [1.3747, 0.5970, 0.7401],\n",
       "          ...,\n",
       "          [0.8588, 1.3154, 0.9325],\n",
       "          [0.2591, 1.8488, 1.6379],\n",
       "          [1.4164, 1.4934, 0.8091]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.7057, 0.9913, 0.6406],\n",
       "          [0.7386, 0.7841, 0.4551],\n",
       "          [0.7034, 1.4171, 0.8453],\n",
       "          ...,\n",
       "          [0.6315, 1.0731, 0.7721],\n",
       "          [1.5655, 0.9291, 0.8604],\n",
       "          [1.5856, 1.3146, 1.6415]],\n",
       "\n",
       "         [[0.0751, 0.7783, 0.6193],\n",
       "          [0.6978, 0.9448, 0.7544],\n",
       "          [0.3352, 1.3481, 0.3476],\n",
       "          ...,\n",
       "          [0.8735, 0.5122, 1.4695],\n",
       "          [1.2755, 1.4790, 1.5823],\n",
       "          [1.3225, 1.4562, 1.3800]],\n",
       "\n",
       "         [[1.3986, 1.5775, 0.5669],\n",
       "          [0.8419, 0.8892, 0.7904],\n",
       "          [0.9367, 1.1258, 1.5188],\n",
       "          ...,\n",
       "          [0.2702, 1.8007, 1.3342],\n",
       "          [1.1775, 0.7414, 1.3258],\n",
       "          [1.1353, 0.9540, 0.5985]]],\n",
       "\n",
       "\n",
       "        [[[0.8606, 0.6971, 1.1096],\n",
       "          [0.9203, 0.5628, 1.2333],\n",
       "          [1.0217, 0.9528, 1.6183],\n",
       "          ...,\n",
       "          [1.0745, 1.6889, 1.0789],\n",
       "          [1.6582, 0.7878, 1.0226],\n",
       "          [0.7489, 1.2835, 0.9896]],\n",
       "\n",
       "         [[1.1016, 1.2161, 1.2570],\n",
       "          [1.4427, 0.3053, 1.1846],\n",
       "          [1.1610, 1.1015, 0.8121],\n",
       "          ...,\n",
       "          [0.7949, 1.3250, 0.7954],\n",
       "          [1.5239, 1.6063, 0.2615],\n",
       "          [0.3929, 0.9395, 0.3853]],\n",
       "\n",
       "         [[0.8872, 0.3384, 0.9056],\n",
       "          [1.6829, 1.3401, 0.6563],\n",
       "          [1.2259, 0.6165, 0.4837],\n",
       "          ...,\n",
       "          [1.4918, 1.6144, 1.2900],\n",
       "          [0.9969, 1.6407, 1.7053],\n",
       "          [1.4485, 1.3837, 1.6682]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.6747, 0.9019, 1.5321],\n",
       "          [0.4306, 0.7381, 0.2996],\n",
       "          [0.8859, 1.1637, 0.4689],\n",
       "          ...,\n",
       "          [0.2757, 0.8674, 1.4653],\n",
       "          [0.8321, 1.5904, 0.3267],\n",
       "          [1.6840, 1.3975, 1.5555]],\n",
       "\n",
       "         [[0.1908, 1.3958, 0.4307],\n",
       "          [0.5431, 1.3501, 1.2029],\n",
       "          [0.8246, 1.4769, 0.7210],\n",
       "          ...,\n",
       "          [0.9963, 0.8801, 1.2031],\n",
       "          [1.1901, 0.6583, 1.2393],\n",
       "          [0.6012, 1.7158, 1.1637]],\n",
       "\n",
       "         [[1.8231, 1.2654, 1.0136],\n",
       "          [1.0222, 1.7591, 1.2862],\n",
       "          [1.8566, 1.4297, 1.5681],\n",
       "          ...,\n",
       "          [0.4526, 1.9631, 1.4562],\n",
       "          [0.6827, 0.7534, 1.4168],\n",
       "          [1.0800, 1.0681, 1.1398]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[1.1499, 1.0341, 0.5286],\n",
       "          [0.8590, 0.3510, 1.2811],\n",
       "          [0.8171, 0.8212, 1.0706],\n",
       "          ...,\n",
       "          [0.1778, 1.0418, 0.8836],\n",
       "          [1.7179, 1.4768, 1.0492],\n",
       "          [0.6930, 0.6050, 1.1389]],\n",
       "\n",
       "         [[0.3201, 1.1564, 0.9785],\n",
       "          [0.8384, 0.4419, 1.1266],\n",
       "          [1.1854, 0.8426, 1.3807],\n",
       "          ...,\n",
       "          [1.5327, 1.0033, 1.4024],\n",
       "          [1.5040, 1.2431, 0.3039],\n",
       "          [1.0060, 1.5919, 0.2433]],\n",
       "\n",
       "         [[1.1824, 1.0752, 0.8628],\n",
       "          [0.8705, 1.4593, 0.4797],\n",
       "          [0.7609, 0.7390, 0.7110],\n",
       "          ...,\n",
       "          [1.0932, 1.1520, 1.5042],\n",
       "          [0.1344, 1.2574, 1.7339],\n",
       "          [0.7633, 0.7882, 0.9376]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.1299, 0.3176, 1.2620],\n",
       "          [0.3068, 0.3142, 0.1452],\n",
       "          [1.1638, 1.2988, 0.4252],\n",
       "          ...,\n",
       "          [0.9850, 0.8713, 1.4552],\n",
       "          [1.5677, 1.0593, 0.5389],\n",
       "          [1.7322, 0.9979, 1.6454]],\n",
       "\n",
       "         [[0.2952, 0.9506, 0.6238],\n",
       "          [0.8072, 1.0539, 1.2358],\n",
       "          [0.7512, 1.7497, 0.2404],\n",
       "          ...,\n",
       "          [1.6554, 0.8294, 1.2353],\n",
       "          [0.5890, 1.3949, 1.3516],\n",
       "          [1.0112, 1.8041, 0.7345]],\n",
       "\n",
       "         [[1.5635, 0.9276, 0.4626],\n",
       "          [1.2832, 1.5482, 1.2085],\n",
       "          [1.0416, 0.9516, 1.3996],\n",
       "          ...,\n",
       "          [0.4044, 1.3113, 1.2384],\n",
       "          [0.7545, 1.2474, 0.5935],\n",
       "          [0.8411, 1.1511, 0.6549]]],\n",
       "\n",
       "\n",
       "        [[[1.0926, 0.9153, 0.8972],\n",
       "          [1.3768, 0.1096, 1.1532],\n",
       "          [1.3253, 0.6221, 1.6217],\n",
       "          ...,\n",
       "          [0.4726, 1.0844, 0.8380],\n",
       "          [1.6568, 1.5095, 1.1078],\n",
       "          [1.1864, 0.4328, 0.9208]],\n",
       "\n",
       "         [[0.6682, 1.6530, 1.2798],\n",
       "          [0.6249, 0.4656, 1.3346],\n",
       "          [1.3915, 0.6783, 0.6606],\n",
       "          ...,\n",
       "          [0.8013, 1.1797, 1.5609],\n",
       "          [1.8169, 1.0945, 0.9964],\n",
       "          [1.0496, 1.7630, 0.1238]],\n",
       "\n",
       "         [[0.6559, 0.7423, 0.6356],\n",
       "          [1.0883, 1.7989, 0.5868],\n",
       "          [1.3245, 1.1334, 0.8181],\n",
       "          ...,\n",
       "          [1.3320, 1.2104, 1.3106],\n",
       "          [0.5163, 0.9316, 1.5609],\n",
       "          [0.7139, 1.6214, 0.9655]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.3946, 0.9068, 1.4450],\n",
       "          [0.2918, 0.2021, 0.7610],\n",
       "          [1.3650, 1.7062, 0.7017],\n",
       "          ...,\n",
       "          [1.1467, 0.9456, 0.9335],\n",
       "          [0.9112, 1.1325, 0.9657],\n",
       "          [0.8696, 1.1441, 0.7911]],\n",
       "\n",
       "         [[0.4641, 0.6941, 0.6583],\n",
       "          [0.3890, 1.6744, 0.8371],\n",
       "          [0.4961, 1.7336, 0.9789],\n",
       "          ...,\n",
       "          [0.7206, 0.7472, 1.5941],\n",
       "          [1.3027, 0.8392, 1.1918],\n",
       "          [1.4107, 1.4624, 1.0104]],\n",
       "\n",
       "         [[1.1288, 1.5144, 0.7226],\n",
       "          [0.7181, 1.1752, 1.0849],\n",
       "          [0.9011, 1.4475, 1.2244],\n",
       "          ...,\n",
       "          [0.9052, 1.1268, 1.1131],\n",
       "          [0.7039, 0.4965, 1.3586],\n",
       "          [0.7201, 0.5213, 0.7737]]],\n",
       "\n",
       "\n",
       "        [[[0.8626, 0.8550, 0.2686],\n",
       "          [0.9900, 0.2761, 0.8898],\n",
       "          [0.9709, 0.7152, 1.8352],\n",
       "          ...,\n",
       "          [0.9190, 1.0509, 0.2631],\n",
       "          [1.0561, 0.7722, 1.0458],\n",
       "          [0.6016, 1.3737, 1.1304]],\n",
       "\n",
       "         [[0.9262, 1.7671, 1.1586],\n",
       "          [1.0002, 0.3568, 1.7664],\n",
       "          [1.2515, 0.8065, 1.3973],\n",
       "          ...,\n",
       "          [0.9918, 1.4118, 1.1720],\n",
       "          [1.4213, 0.7142, 0.9685],\n",
       "          [1.3044, 1.6436, 0.6596]],\n",
       "\n",
       "         [[0.8699, 0.6066, 0.8113],\n",
       "          [1.5375, 1.6629, 1.2898],\n",
       "          [0.7745, 0.7180, 0.8494],\n",
       "          ...,\n",
       "          [1.5735, 1.6009, 1.4997],\n",
       "          [0.7259, 1.5092, 1.4210],\n",
       "          [1.0421, 1.2574, 1.6942]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.3196, 0.3173, 0.5993],\n",
       "          [0.8222, 0.6419, 0.8809],\n",
       "          [1.3805, 1.0708, 1.0269],\n",
       "          ...,\n",
       "          [0.2332, 0.6852, 1.0316],\n",
       "          [1.1767, 1.1206, 0.8770],\n",
       "          [1.5794, 1.3931, 0.9609]],\n",
       "\n",
       "         [[0.0887, 0.9084, 0.5469],\n",
       "          [0.5252, 1.3129, 0.3699],\n",
       "          [0.4800, 1.7183, 0.9579],\n",
       "          ...,\n",
       "          [0.7872, 0.8491, 1.4955],\n",
       "          [0.9974, 1.0369, 1.1060],\n",
       "          [0.6492, 1.8693, 1.2384]],\n",
       "\n",
       "         [[1.5866, 0.8957, 0.5136],\n",
       "          [0.4493, 1.0216, 1.2810],\n",
       "          [1.2253, 0.7465, 1.2451],\n",
       "          ...,\n",
       "          [0.8216, 1.9601, 1.3455],\n",
       "          [0.9052, 1.1012, 0.5548],\n",
       "          [1.3574, 0.8075, 0.3509]]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果：計算可能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例5) (32, 128, 128, 3)と(128, 128, 6)の演算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((32, 128, 128, 3))\n",
    "b = torch.rand((128, 128, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (6) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (6) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一番右のRankが両者で異なるので、ブロードキャスティングできない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例6) (1, 128, 128, 3)と(8, 128, 128, 1)の演算  \n",
    "rank0では前者が、rank3では後者の次元が低いtensorの場合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((1, 128, 128, 3))\n",
    "b = torch.rand((8, 128, 128, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5604, 0.3802, 0.9534],\n",
       "          [0.7845, 1.2659, 0.9637],\n",
       "          [1.1564, 1.5344, 1.0868],\n",
       "          ...,\n",
       "          [1.0127, 0.9974, 1.5632],\n",
       "          [1.3757, 0.9418, 1.5401],\n",
       "          [1.3365, 0.6936, 0.8698]],\n",
       "\n",
       "         [[0.1989, 0.9930, 0.6176],\n",
       "          [1.0474, 1.0387, 0.9743],\n",
       "          [0.4889, 0.7482, 0.3083],\n",
       "          ...,\n",
       "          [0.7021, 1.0262, 1.0312],\n",
       "          [0.9161, 0.9434, 0.7452],\n",
       "          [1.0048, 1.4666, 1.1286]],\n",
       "\n",
       "         [[1.4104, 1.4833, 1.6604],\n",
       "          [0.6810, 0.9959, 0.4219],\n",
       "          [1.1556, 1.3073, 1.0011],\n",
       "          ...,\n",
       "          [0.7069, 1.1351, 0.2913],\n",
       "          [1.5982, 1.1518, 1.2421],\n",
       "          [0.9593, 1.1763, 1.6168]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.2587, 0.8883, 1.3228],\n",
       "          [0.8341, 1.1248, 1.1193],\n",
       "          [0.5390, 0.8507, 0.2386],\n",
       "          ...,\n",
       "          [1.0532, 0.8762, 0.9433],\n",
       "          [0.6722, 0.8187, 1.0094],\n",
       "          [1.7713, 1.2609, 1.6200]],\n",
       "\n",
       "         [[0.8755, 0.3195, 0.7582],\n",
       "          [1.5264, 1.0135, 1.2062],\n",
       "          [1.0851, 1.9094, 1.3761],\n",
       "          ...,\n",
       "          [0.6151, 0.5036, 0.5615],\n",
       "          [0.7772, 0.4437, 0.6074],\n",
       "          [0.4191, 0.3062, 0.3625]],\n",
       "\n",
       "         [[1.0139, 1.7288, 1.2679],\n",
       "          [1.2263, 1.6615, 1.6788],\n",
       "          [0.9230, 0.4382, 0.6815],\n",
       "          ...,\n",
       "          [0.9642, 1.4786, 0.8353],\n",
       "          [1.0061, 1.3876, 1.3042],\n",
       "          [1.0119, 0.5217, 0.7980]]],\n",
       "\n",
       "\n",
       "        [[[0.4562, 0.2760, 0.8492],\n",
       "          [0.6425, 1.1239, 0.8218],\n",
       "          [1.0537, 1.4317, 0.9841],\n",
       "          ...,\n",
       "          [0.8565, 0.8412, 1.4070],\n",
       "          [0.7109, 0.2769, 0.8752],\n",
       "          [1.4176, 0.7748, 0.9510]],\n",
       "\n",
       "         [[0.6415, 1.4356, 1.0602],\n",
       "          [1.3917, 1.3831, 1.3186],\n",
       "          [0.7802, 1.0395, 0.5996],\n",
       "          ...,\n",
       "          [0.7352, 1.0593, 1.0643],\n",
       "          [0.7196, 0.7469, 0.5487],\n",
       "          [0.5292, 0.9910, 0.6529]],\n",
       "\n",
       "         [[0.9245, 0.9974, 1.1744],\n",
       "          [0.8294, 1.1444, 0.5703],\n",
       "          [0.7099, 0.8616, 0.5554],\n",
       "          ...,\n",
       "          [1.4063, 1.8345, 0.9908],\n",
       "          [1.5718, 1.1254, 1.2157],\n",
       "          [0.3536, 0.5706, 1.0111]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.3174, 0.9470, 1.3814],\n",
       "          [0.5719, 0.8626, 0.8570],\n",
       "          [0.6000, 0.9117, 0.2996],\n",
       "          ...,\n",
       "          [1.4235, 1.2466, 1.3137],\n",
       "          [0.9512, 1.0977, 1.2884],\n",
       "          [1.7841, 1.2737, 1.6329]],\n",
       "\n",
       "         [[1.0268, 0.4708, 0.9095],\n",
       "          [1.0291, 0.5162, 0.7088],\n",
       "          [1.0070, 1.8313, 1.2979],\n",
       "          ...,\n",
       "          [1.2041, 1.0926, 1.1505],\n",
       "          [1.0885, 0.7550, 0.9187],\n",
       "          [0.6466, 0.5337, 0.5900]],\n",
       "\n",
       "         [[0.3734, 1.0883, 0.6274],\n",
       "          [1.1148, 1.5499, 1.5672],\n",
       "          [1.3656, 0.8807, 1.1240],\n",
       "          ...,\n",
       "          [0.7304, 1.2448, 0.6015],\n",
       "          [0.5228, 0.9043, 0.8209],\n",
       "          [1.2193, 0.7291, 1.0055]]],\n",
       "\n",
       "\n",
       "        [[[0.5885, 0.4084, 0.9816],\n",
       "          [0.6148, 1.0962, 0.7941],\n",
       "          [0.9373, 1.3154, 0.8677],\n",
       "          ...,\n",
       "          [0.6006, 0.5852, 1.1511],\n",
       "          [1.2716, 0.8377, 1.4359],\n",
       "          [0.9408, 0.2980, 0.4742]],\n",
       "\n",
       "         [[0.8571, 1.6511, 1.2757],\n",
       "          [1.4775, 1.4688, 1.4044],\n",
       "          [0.3728, 0.6321, 0.1921],\n",
       "          ...,\n",
       "          [0.4415, 0.7656, 0.7706],\n",
       "          [1.2877, 1.3150, 1.1168],\n",
       "          [0.3338, 0.7956, 0.4576]],\n",
       "\n",
       "         [[0.9272, 1.0000, 1.1771],\n",
       "          [0.6690, 0.9839, 0.4098],\n",
       "          [0.6468, 0.7985, 0.4923],\n",
       "          ...,\n",
       "          [0.6313, 1.0596, 0.2158],\n",
       "          [0.8157, 0.3692, 0.4596],\n",
       "          [0.3845, 0.6014, 1.0419]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.7186, 1.3482, 1.7827],\n",
       "          [0.8537, 1.1444, 1.1388],\n",
       "          [0.5233, 0.8350, 0.2229],\n",
       "          ...,\n",
       "          [1.5580, 1.3810, 1.4481],\n",
       "          [0.7332, 0.8797, 1.0704],\n",
       "          [1.9181, 1.4076, 1.7668]],\n",
       "\n",
       "         [[1.0032, 0.4472, 0.8859],\n",
       "          [0.7923, 0.2794, 0.4721],\n",
       "          [0.3363, 1.1606, 0.6272],\n",
       "          ...,\n",
       "          [0.6992, 0.5877, 0.6456],\n",
       "          [1.5067, 1.1732, 1.3369],\n",
       "          [0.8802, 0.7673, 0.8236]],\n",
       "\n",
       "         [[0.2533, 0.9682, 0.5073],\n",
       "          [1.2460, 1.6812, 1.6985],\n",
       "          [1.1832, 0.6984, 0.9417],\n",
       "          ...,\n",
       "          [0.8923, 1.4067, 0.7634],\n",
       "          [0.5937, 0.9752, 0.8918],\n",
       "          [1.3920, 0.9018, 1.1782]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[1.1224, 0.9423, 1.5155],\n",
       "          [1.3108, 1.7922, 1.4900],\n",
       "          [0.8049, 1.1829, 0.7353],\n",
       "          ...,\n",
       "          [1.0420, 1.0267, 1.5925],\n",
       "          [1.2237, 0.7897, 1.3880],\n",
       "          [1.4151, 0.7722, 0.9485]],\n",
       "\n",
       "         [[1.1230, 1.9170, 1.5416],\n",
       "          [1.4477, 1.4391, 1.3746],\n",
       "          [1.1159, 1.3752, 0.9353],\n",
       "          ...,\n",
       "          [0.9083, 1.2324, 1.2374],\n",
       "          [0.7687, 0.7960, 0.5978],\n",
       "          [0.3923, 0.8541, 0.5161]],\n",
       "\n",
       "         [[1.5606, 1.6335, 1.8105],\n",
       "          [1.0653, 1.3802, 0.8061],\n",
       "          [0.4302, 0.5819, 0.2756],\n",
       "          ...,\n",
       "          [1.0731, 1.5013, 0.6575],\n",
       "          [1.6223, 1.1759, 1.2663],\n",
       "          [0.8914, 1.1084, 1.5489]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.0448, 0.6745, 1.1089],\n",
       "          [1.0263, 1.3171, 1.3115],\n",
       "          [0.8421, 1.1539, 0.5418],\n",
       "          ...,\n",
       "          [1.3743, 1.1974, 1.2645],\n",
       "          [0.3084, 0.4549, 0.6456],\n",
       "          [1.2428, 0.7324, 1.0915]],\n",
       "\n",
       "         [[1.4485, 0.8925, 1.3312],\n",
       "          [1.3892, 0.8763, 1.0690],\n",
       "          [0.6191, 1.4434, 0.9100],\n",
       "          ...,\n",
       "          [0.9325, 0.8210, 0.8789],\n",
       "          [1.3783, 1.0448, 1.2085],\n",
       "          [1.0784, 0.9655, 1.0218]],\n",
       "\n",
       "         [[0.7672, 1.4822, 1.0212],\n",
       "          [1.4270, 1.8621, 1.8795],\n",
       "          [1.2054, 0.7206, 0.9639],\n",
       "          ...,\n",
       "          [0.8793, 1.3937, 0.7504],\n",
       "          [1.1574, 1.5389, 1.4555],\n",
       "          [0.8024, 0.3122, 0.5885]]],\n",
       "\n",
       "\n",
       "        [[[1.1719, 0.9917, 1.5649],\n",
       "          [0.5274, 1.0089, 0.7067],\n",
       "          [1.2508, 1.6289, 1.1812],\n",
       "          ...,\n",
       "          [1.0639, 1.0486, 1.6144],\n",
       "          [0.6948, 0.2609, 0.8592],\n",
       "          [1.6655, 1.0227, 1.1989]],\n",
       "\n",
       "         [[0.7219, 1.5159, 1.1406],\n",
       "          [0.7657, 0.7570, 0.6926],\n",
       "          [0.7783, 1.0377, 0.5977],\n",
       "          ...,\n",
       "          [0.4863, 0.8104, 0.8154],\n",
       "          [0.7919, 0.8192, 0.6210],\n",
       "          [0.7040, 1.1658, 0.8277]],\n",
       "\n",
       "         [[0.7948, 0.8677, 1.0448],\n",
       "          [1.2817, 1.5967, 1.0226],\n",
       "          [0.4373, 0.5890, 0.2827],\n",
       "          ...,\n",
       "          [1.1453, 1.5736, 0.7298],\n",
       "          [1.4159, 0.9695, 1.0598],\n",
       "          [0.3270, 0.5440, 0.9845]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.2109, 0.8405, 1.2749],\n",
       "          [0.6948, 0.9856, 0.9800],\n",
       "          [0.6164, 0.9282, 0.3161],\n",
       "          ...,\n",
       "          [1.1910, 1.0140, 1.0811],\n",
       "          [0.7827, 0.9292, 1.1199],\n",
       "          [1.0866, 0.5762, 0.9353]],\n",
       "\n",
       "         [[1.2419, 0.6859, 1.1246],\n",
       "          [1.3643, 0.8514, 1.0441],\n",
       "          [0.5885, 1.4128, 0.8794],\n",
       "          ...,\n",
       "          [1.3808, 1.2693, 1.3272],\n",
       "          [1.3522, 1.0187, 1.1825],\n",
       "          [0.6648, 0.5520, 0.6082]],\n",
       "\n",
       "         [[0.5735, 1.2885, 0.8276],\n",
       "          [0.9860, 1.4211, 1.4385],\n",
       "          [1.2905, 0.8056, 1.0490],\n",
       "          ...,\n",
       "          [1.2993, 1.8137, 1.1704],\n",
       "          [0.7858, 1.1673, 1.0839],\n",
       "          [1.5244, 1.0342, 1.3106]]],\n",
       "\n",
       "\n",
       "        [[[0.3533, 0.1731, 0.7464],\n",
       "          [1.3605, 1.8420, 1.5398],\n",
       "          [0.4801, 0.8581, 0.4105],\n",
       "          ...,\n",
       "          [0.9265, 0.9112, 1.4770],\n",
       "          [1.5437, 1.1098, 1.7080],\n",
       "          [1.4908, 0.8480, 1.0242]],\n",
       "\n",
       "         [[0.8126, 1.6066, 1.2312],\n",
       "          [1.7484, 1.7398, 1.6753],\n",
       "          [0.5883, 0.8477, 0.4077],\n",
       "          ...,\n",
       "          [0.5892, 0.9133, 0.9183],\n",
       "          [1.4318, 1.4591, 1.2609],\n",
       "          [0.6502, 1.1120, 0.7739]],\n",
       "\n",
       "         [[1.5300, 1.6029, 1.7799],\n",
       "          [0.9258, 1.2407, 0.6667],\n",
       "          [0.5539, 0.7056, 0.3994],\n",
       "          ...,\n",
       "          [0.7190, 1.1472, 0.3034],\n",
       "          [1.1566, 0.7102, 0.8005],\n",
       "          [0.4564, 0.6734, 1.1139]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.3432, 0.9728, 1.4072],\n",
       "          [0.8655, 1.1563, 1.1507],\n",
       "          [1.1185, 1.4302, 0.8181],\n",
       "          ...,\n",
       "          [1.5317, 1.3548, 1.4219],\n",
       "          [0.7309, 0.8774, 1.0681],\n",
       "          [1.6917, 1.1813, 1.5405]],\n",
       "\n",
       "         [[1.1033, 0.5473, 0.9860],\n",
       "          [1.0577, 0.5449, 0.7375],\n",
       "          [0.7720, 1.5963, 1.0629],\n",
       "          ...,\n",
       "          [1.4452, 1.3337, 1.3916],\n",
       "          [1.1961, 0.8626, 1.0263],\n",
       "          [1.1793, 1.0664, 1.1226]],\n",
       "\n",
       "         [[0.3605, 1.0755, 0.6145],\n",
       "          [0.6679, 1.1030, 1.1204],\n",
       "          [0.9007, 0.4159, 0.6592],\n",
       "          ...,\n",
       "          [0.7614, 1.2758, 0.6325],\n",
       "          [0.8285, 1.2101, 1.1267],\n",
       "          [1.3602, 0.8700, 1.1463]]]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128, 128, 3])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a+b).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aとbの両方ブロードキャスティングされるので、これは演算可能。  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
