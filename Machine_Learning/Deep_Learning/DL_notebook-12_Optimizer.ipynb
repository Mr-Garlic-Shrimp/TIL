{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深層学習ノートブック-12 Optimizer\n",
    "学習ループのコードの保守性を高めるために、パラメータの更新する部分をOptimizerクラスにまとめる。  \n",
    "* 学習の対象となるparametersおよびlr(学習率)をインスタンスの引数に渡す\n",
    "* step()メソッドにて各パラメータを更新する処理を記述する\n",
    "* zero_grad()メソッドにて各パラメータの勾配をゼロにする処理を記述する  \n",
    "\n",
    "参考：  \n",
    "* [Udemy講座：「①米国AI開発者がやさしく教える深層学習超入門第一弾【Pythonで実践】」](https://www.udemy.com/course/deeplearning1/learn/lecture/40143418)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_1(nn.Module):\n",
    "    def __init__(self, num_in, num_hidden, num_out):\n",
    "        # 親クラスのinitを呼び出す。\n",
    "        super().__init__()\n",
    "        # 全結合層はパラメタを持つのでnn.で定義する\n",
    "        # num_in, num_hidden, num_outを渡すことにより全結合層を実体化させる\n",
    "        self.linear_1 = nn.Linear(num_in, num_hidden)\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_out)\n",
    "\n",
    "    # nn.Moduleにもforwardメソッドがあり、ここでオーバーライドしている。\n",
    "    def forward(self, x):\n",
    "        # デバッグ用\n",
    "        # z1 = self.linear_1(z)\n",
    "        # a1 = F.relu(z1)\n",
    "        # z2 = self.linear_2(a1)\n",
    "        # 隠れ層の線形変換 →ReLu適用→ 隠れ層の線形変換を一気にやっている。\n",
    "        z = self.linear_2( F.relu( self.linear_1(x)) )\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP_1(\n",
       "  (linear_1): Linear(in_features=64, out_features=30, bias=True)\n",
       "  (linear_2): Linear(in_features=30, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNISTデータセットの読み込み\n",
    "dataset = datasets.load_digits()\n",
    "X = torch.tensor( dataset.data , dtype=torch.float32) \n",
    "y = torch.tensor( dataset.target)\n",
    "# ★ F.cross_entropyの仕様的にはone_hotの形にする必要はない\n",
    "# y = F.one_hot(y, num_classes=10) \n",
    "\n",
    "# hold-out\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 標準化\n",
    "train_mean, train_std = X_train.mean(), X_train.std()\n",
    "X_train = (X_train - train_mean) / train_std\n",
    "X_val = (X_val - train_mean) / train_std\n",
    "\n",
    "# モデルのコンストラクタに渡す引数を定義\n",
    "num_in = 64\n",
    "num_hidden = 30\n",
    "num_out = 10\n",
    "\n",
    "# モデル定義（２層のMLP）\n",
    "MLP_model = MLP_1(num_in=num_in, num_hidden=num_hidden, num_out=num_out)\n",
    "# requires_grad_をTrueに設定。最後に_がつくのは設定するという意味。\n",
    "MLP_model.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0: {'Loss_train': 2.197762359513177, 'Loss_val': 2.0313637256622314, 'Accuracy': 0.4305555522441864}\n",
      "epoch_1: {'Loss_train': 1.7720867156982423, 'Loss_val': 1.5172945261001587, 'Accuracy': 0.7055555582046509}\n",
      "epoch_2: {'Loss_train': 1.237720595465766, 'Loss_val': 1.011123538017273, 'Accuracy': 0.8527777791023254}\n",
      "epoch_3: {'Loss_train': 0.8398983942137824, 'Loss_val': 0.6964869499206543, 'Accuracy': 0.8833333253860474}\n",
      "epoch_4: {'Loss_train': 0.6075527045461867, 'Loss_val': 0.5220246911048889, 'Accuracy': 0.8916666507720947}\n",
      "epoch_5: {'Loss_train': 0.4724813885158963, 'Loss_val': 0.4250306487083435, 'Accuracy': 0.9083333611488342}\n",
      "epoch_6: {'Loss_train': 0.38948921627468536, 'Loss_val': 0.3576592803001404, 'Accuracy': 0.9166666865348816}\n",
      "epoch_7: {'Loss_train': 0.3315896646844016, 'Loss_val': 0.30983641743659973, 'Accuracy': 0.9388889074325562}\n",
      "epoch_8: {'Loss_train': 0.2905773745642768, 'Loss_val': 0.2770136296749115, 'Accuracy': 0.9388889074325562}\n",
      "epoch_9: {'Loss_train': 0.2599299869603581, 'Loss_val': 0.24965232610702515, 'Accuracy': 0.9444444179534912}\n",
      "epoch_10: {'Loss_train': 0.2374467886156506, 'Loss_val': 0.23201070725917816, 'Accuracy': 0.9416666626930237}\n",
      "epoch_11: {'Loss_train': 0.21799162758721247, 'Loss_val': 0.21499282121658325, 'Accuracy': 0.9555555582046509}\n",
      "epoch_12: {'Loss_train': 0.20194436311721803, 'Loss_val': 0.20195142924785614, 'Accuracy': 0.949999988079071}\n",
      "epoch_13: {'Loss_train': 0.188869836098618, 'Loss_val': 0.19234305620193481, 'Accuracy': 0.9555555582046509}\n",
      "epoch_14: {'Loss_train': 0.17766095573703447, 'Loss_val': 0.1817885786294937, 'Accuracy': 0.9583333134651184}\n",
      "epoch_15: {'Loss_train': 0.16922678881221348, 'Loss_val': 0.1728334277868271, 'Accuracy': 0.9611111283302307}\n",
      "epoch_16: {'Loss_train': 0.16035087878505389, 'Loss_val': 0.17000575363636017, 'Accuracy': 0.9583333134651184}\n",
      "epoch_17: {'Loss_train': 0.15333472655879127, 'Loss_val': 0.163278728723526, 'Accuracy': 0.9638888835906982}\n",
      "epoch_18: {'Loss_train': 0.14703968250089222, 'Loss_val': 0.15700891613960266, 'Accuracy': 0.9638888835906982}\n",
      "epoch_19: {'Loss_train': 0.1409045793943935, 'Loss_val': 0.15242183208465576, 'Accuracy': 0.9638888835906982}\n",
      "epoch_20: {'Loss_train': 0.13584391524394354, 'Loss_val': 0.1483517438173294, 'Accuracy': 0.9638888835906982}\n",
      "epoch_21: {'Loss_train': 0.13094548309842746, 'Loss_val': 0.14407043159008026, 'Accuracy': 0.9666666388511658}\n",
      "epoch_22: {'Loss_train': 0.1259999107155535, 'Loss_val': 0.14243562519550323, 'Accuracy': 0.9666666388511658}\n",
      "epoch_23: {'Loss_train': 0.12179978572660022, 'Loss_val': 0.13936182856559753, 'Accuracy': 0.9611111283302307}\n",
      "epoch_24: {'Loss_train': 0.11830557328131464, 'Loss_val': 0.13501577079296112, 'Accuracy': 0.9666666388511658}\n",
      "epoch_25: {'Loss_train': 0.11435555219650269, 'Loss_val': 0.1344011127948761, 'Accuracy': 0.9638888835906982}\n",
      "epoch_26: {'Loss_train': 0.11178845432069566, 'Loss_val': 0.13221628963947296, 'Accuracy': 0.9666666388511658}\n",
      "epoch_27: {'Loss_train': 0.10890691255529722, 'Loss_val': 0.12951713800430298, 'Accuracy': 0.9666666388511658}\n",
      "epoch_28: {'Loss_train': 0.10501370210614469, 'Loss_val': 0.12776057422161102, 'Accuracy': 0.9694444537162781}\n",
      "epoch_29: {'Loss_train': 0.1034467970745431, 'Loss_val': 0.1284894347190857, 'Accuracy': 0.9611111283302307}\n",
      "epoch_30: {'Loss_train': 0.10025423818992243, 'Loss_val': 0.12439009547233582, 'Accuracy': 0.9611111283302307}\n",
      "epoch_31: {'Loss_train': 0.09763903241190645, 'Loss_val': 0.12169351428747177, 'Accuracy': 0.9666666388511658}\n",
      "epoch_32: {'Loss_train': 0.09593473424514135, 'Loss_val': 0.12475015968084335, 'Accuracy': 0.9611111283302307}\n",
      "epoch_33: {'Loss_train': 0.09321676592032115, 'Loss_val': 0.11901194602251053, 'Accuracy': 0.9666666388511658}\n",
      "epoch_34: {'Loss_train': 0.0910957932472229, 'Loss_val': 0.12047075480222702, 'Accuracy': 0.9638888835906982}\n",
      "epoch_35: {'Loss_train': 0.08985946435067389, 'Loss_val': 0.11870316416025162, 'Accuracy': 0.9611111283302307}\n",
      "epoch_36: {'Loss_train': 0.08714296815709935, 'Loss_val': 0.11727584898471832, 'Accuracy': 0.9666666388511658}\n",
      "epoch_37: {'Loss_train': 0.08512930853499306, 'Loss_val': 0.11693122982978821, 'Accuracy': 0.9638888835906982}\n",
      "epoch_38: {'Loss_train': 0.08351710438728333, 'Loss_val': 0.11497852206230164, 'Accuracy': 0.9638888835906982}\n",
      "epoch_39: {'Loss_train': 0.08158270253075493, 'Loss_val': 0.11513614654541016, 'Accuracy': 0.9638888835906982}\n",
      "epoch_40: {'Loss_train': 0.08029238627188735, 'Loss_val': 0.11279277503490448, 'Accuracy': 0.9611111283302307}\n",
      "epoch_41: {'Loss_train': 0.07816946270565192, 'Loss_val': 0.11261330544948578, 'Accuracy': 0.9611111283302307}\n",
      "epoch_42: {'Loss_train': 0.07644216594182783, 'Loss_val': 0.11234568804502487, 'Accuracy': 0.9611111283302307}\n",
      "epoch_43: {'Loss_train': 0.07541483350925976, 'Loss_val': 0.1119299903512001, 'Accuracy': 0.9638888835906982}\n",
      "epoch_44: {'Loss_train': 0.07394802222649256, 'Loss_val': 0.11013872176408768, 'Accuracy': 0.9666666388511658}\n",
      "epoch_45: {'Loss_train': 0.0725933376699686, 'Loss_val': 0.10892661660909653, 'Accuracy': 0.9694444537162781}\n",
      "epoch_46: {'Loss_train': 0.0705905863808261, 'Loss_val': 0.10898514091968536, 'Accuracy': 0.9611111283302307}\n",
      "epoch_47: {'Loss_train': 0.06970806899997924, 'Loss_val': 0.10889002680778503, 'Accuracy': 0.9611111283302307}\n",
      "epoch_48: {'Loss_train': 0.0684420999346508, 'Loss_val': 0.10790814459323883, 'Accuracy': 0.9694444537162781}\n",
      "epoch_49: {'Loss_train': 0.06698148703823487, 'Loss_val': 0.10640525072813034, 'Accuracy': 0.9722222089767456}\n",
      "epoch_50: {'Loss_train': 0.0658777347455422, 'Loss_val': 0.10566601157188416, 'Accuracy': 0.9750000238418579}\n",
      "epoch_51: {'Loss_train': 0.06460465341806412, 'Loss_val': 0.10870610177516937, 'Accuracy': 0.9638888835906982}\n",
      "epoch_52: {'Loss_train': 0.06382302012708452, 'Loss_val': 0.10709119588136673, 'Accuracy': 0.9638888835906982}\n",
      "epoch_53: {'Loss_train': 0.06215568785038259, 'Loss_val': 0.10693910717964172, 'Accuracy': 0.9638888835906982}\n",
      "epoch_54: {'Loss_train': 0.061856664137707816, 'Loss_val': 0.10512200742959976, 'Accuracy': 0.9694444537162781}\n",
      "epoch_55: {'Loss_train': 0.0600057414215472, 'Loss_val': 0.10526276379823685, 'Accuracy': 0.9638888835906982}\n",
      "epoch_56: {'Loss_train': 0.059077566800018154, 'Loss_val': 0.10387170314788818, 'Accuracy': 0.9666666388511658}\n",
      "epoch_57: {'Loss_train': 0.058300242904159756, 'Loss_val': 0.1035979613661766, 'Accuracy': 0.9666666388511658}\n",
      "epoch_58: {'Loss_train': 0.056710634691019855, 'Loss_val': 0.10545223951339722, 'Accuracy': 0.9666666388511658}\n",
      "epoch_59: {'Loss_train': 0.05678140359620253, 'Loss_val': 0.10336567461490631, 'Accuracy': 0.9694444537162781}\n",
      "epoch_60: {'Loss_train': 0.05549072264176276, 'Loss_val': 0.10179786384105682, 'Accuracy': 0.9750000238418579}\n",
      "epoch_61: {'Loss_train': 0.054677012293703024, 'Loss_val': 0.10339438170194626, 'Accuracy': 0.9666666388511658}\n",
      "epoch_62: {'Loss_train': 0.0536427497656809, 'Loss_val': 0.10273158550262451, 'Accuracy': 0.9694444537162781}\n",
      "epoch_63: {'Loss_train': 0.05273999143391848, 'Loss_val': 0.10288441926240921, 'Accuracy': 0.9750000238418579}\n",
      "epoch_64: {'Loss_train': 0.05241904072463512, 'Loss_val': 0.10171932727098465, 'Accuracy': 0.9722222089767456}\n",
      "epoch_65: {'Loss_train': 0.051088684052228925, 'Loss_val': 0.1030505895614624, 'Accuracy': 0.9694444537162781}\n",
      "epoch_66: {'Loss_train': 0.050489808743198715, 'Loss_val': 0.10056988149881363, 'Accuracy': 0.9750000238418579}\n",
      "epoch_67: {'Loss_train': 0.04967246568865246, 'Loss_val': 0.10271570086479187, 'Accuracy': 0.9694444537162781}\n",
      "epoch_68: {'Loss_train': 0.04915190252165, 'Loss_val': 0.10145232081413269, 'Accuracy': 0.9694444537162781}\n",
      "epoch_69: {'Loss_train': 0.048323327509893314, 'Loss_val': 0.10080600529909134, 'Accuracy': 0.9722222089767456}\n",
      "epoch_70: {'Loss_train': 0.047367409782277214, 'Loss_val': 0.10001775622367859, 'Accuracy': 0.9750000238418579}\n",
      "epoch_71: {'Loss_train': 0.04674539537065559, 'Loss_val': 0.10061143338680267, 'Accuracy': 0.9694444537162781}\n",
      "epoch_72: {'Loss_train': 0.046065243530190654, 'Loss_val': 0.10009205341339111, 'Accuracy': 0.9722222089767456}\n",
      "epoch_73: {'Loss_train': 0.044961760627726714, 'Loss_val': 0.10017680376768112, 'Accuracy': 0.9722222089767456}\n",
      "epoch_74: {'Loss_train': 0.04469001181423664, 'Loss_val': 0.10097496956586838, 'Accuracy': 0.9694444537162781}\n",
      "epoch_75: {'Loss_train': 0.04415658112201426, 'Loss_val': 0.10079867392778397, 'Accuracy': 0.9694444537162781}\n",
      "epoch_76: {'Loss_train': 0.0436688959495061, 'Loss_val': 0.09996776282787323, 'Accuracy': 0.9722222089767456}\n",
      "epoch_77: {'Loss_train': 0.04280188745922513, 'Loss_val': 0.09881626814603806, 'Accuracy': 0.9750000238418579}\n",
      "epoch_78: {'Loss_train': 0.04237465378310945, 'Loss_val': 0.09854494780302048, 'Accuracy': 0.9750000238418579}\n",
      "epoch_79: {'Loss_train': 0.04121273188955254, 'Loss_val': 0.10102543234825134, 'Accuracy': 0.9694444537162781}\n",
      "epoch_80: {'Loss_train': 0.04095247454113431, 'Loss_val': 0.0997389703989029, 'Accuracy': 0.9722222089767456}\n",
      "epoch_81: {'Loss_train': 0.04001290524999301, 'Loss_val': 0.09899892657995224, 'Accuracy': 0.9750000238418579}\n",
      "epoch_82: {'Loss_train': 0.039673186414357686, 'Loss_val': 0.10090335458517075, 'Accuracy': 0.9694444537162781}\n",
      "epoch_83: {'Loss_train': 0.039363836414284176, 'Loss_val': 0.09945633262395859, 'Accuracy': 0.9750000238418579}\n",
      "epoch_84: {'Loss_train': 0.03868279776846369, 'Loss_val': 0.09956736117601395, 'Accuracy': 0.9722222089767456}\n",
      "epoch_85: {'Loss_train': 0.03784236499211854, 'Loss_val': 0.09946012496948242, 'Accuracy': 0.9722222089767456}\n",
      "epoch_86: {'Loss_train': 0.03785669023378028, 'Loss_val': 0.0996101051568985, 'Accuracy': 0.9722222089767456}\n",
      "epoch_87: {'Loss_train': 0.037236647432049116, 'Loss_val': 0.09891027957201004, 'Accuracy': 0.9750000238418579}\n",
      "epoch_88: {'Loss_train': 0.036614051419827674, 'Loss_val': 0.09879983216524124, 'Accuracy': 0.9750000238418579}\n",
      "epoch_89: {'Loss_train': 0.03605324019574457, 'Loss_val': 0.09890440106391907, 'Accuracy': 0.9750000238418579}\n",
      "epoch_90: {'Loss_train': 0.03560748911566204, 'Loss_val': 0.09951526671648026, 'Accuracy': 0.9750000238418579}\n",
      "epoch_91: {'Loss_train': 0.035182560193869804, 'Loss_val': 0.09941281378269196, 'Accuracy': 0.9750000238418579}\n",
      "epoch_92: {'Loss_train': 0.03475339814192719, 'Loss_val': 0.09960738569498062, 'Accuracy': 0.9750000238418579}\n",
      "epoch_93: {'Loss_train': 0.03393399651265806, 'Loss_val': 0.09874210506677628, 'Accuracy': 0.9750000238418579}\n",
      "epoch_94: {'Loss_train': 0.03328790884051058, 'Loss_val': 0.10286594182252884, 'Accuracy': 0.9694444537162781}\n",
      "epoch_95: {'Loss_train': 0.03370349218861924, 'Loss_val': 0.09946531802415848, 'Accuracy': 0.9750000238418579}\n",
      "epoch_96: {'Loss_train': 0.033204475179728535, 'Loss_val': 0.09954439848661423, 'Accuracy': 0.9722222089767456}\n",
      "epoch_97: {'Loss_train': 0.03283918887997667, 'Loss_val': 0.0997554361820221, 'Accuracy': 0.9722222089767456}\n",
      "epoch_98: {'Loss_train': 0.032191772148427035, 'Loss_val': 0.09867861866950989, 'Accuracy': 0.9750000238418579}\n",
      "epoch_99: {'Loss_train': 0.031918765190574856, 'Loss_val': 0.09953109920024872, 'Accuracy': 0.9722222089767456}\n"
     ]
    }
   ],
   "source": [
    "# バッチサイズとバッチの個数を定義\n",
    "batch_size = 32\n",
    "num_batches = X_train.shape[0] // batch_size + 1\n",
    "learning_rate = 0.03\n",
    "\n",
    "# 学習・検証結果格納用辞書\n",
    "train_results = {}\n",
    "\n",
    "for i, _ in enumerate(range(100)):\n",
    "    #　インデックスをシャッフル\n",
    "    shuffled_indices = np.random.permutation(len(y_train))\n",
    "\n",
    "    # shuffled_indicesからの取り出し範囲初期化\n",
    "    idx_start = 0\n",
    "    idx_end = batch_size\n",
    "\n",
    "    # 各バッチでの学習データに対するlossを累積する用の変数\n",
    "    cum_loss = 0\n",
    "\n",
    "    for _ in range(num_batches):\n",
    "        # 学習データ定義\n",
    "        indices_train = shuffled_indices[ idx_start:idx_end ]\n",
    "        X_train_batch = X_train[indices_train]\n",
    "        y_train_batch = y_train[indices_train]\n",
    "\n",
    "        # 順伝播の計算。F.cross_entropyの中でsoftmaxが適用されるので適用不要\n",
    "        #y_pred = F.softmax(MLP_model(X_train_batch), dim=1)\n",
    "        y_pred = MLP_model(X_train_batch)\n",
    "\n",
    "        # 損失計算\n",
    "        loss = F.cross_entropy(y_pred , y_train_batch)\n",
    "        cum_loss += loss.item()\n",
    "        # 逆伝播の計算\n",
    "        loss.backward()\n",
    "\n",
    "        # パラメタ更新\n",
    "        # with torch.no_grad():\n",
    "        #     MLP_model.linear_1.weight -= learning_rate * MLP_model.linear_1.weight.grad\n",
    "        #     MLP_model.linear_1.bias -= learning_rate * MLP_model.linear_1.bias.grad\n",
    "        #     MLP_model.linear_2.weight -= learning_rate * MLP_model.linear_2.weight.grad\n",
    "        #     MLP_model.linear_2.bias -= learning_rate * MLP_model.linear_2.bias.grad\n",
    "        # ↓この書き方の方が簡単\n",
    "        with torch.no_grad():\n",
    "            for params in MLP_model.parameters():\n",
    "                params -= learning_rate * params.grad\n",
    "\n",
    "        # 勾配初期化。nn.Moduleから継承しているので.zero_gradはそのまま使える。\n",
    "        MLP_model.zero_grad()\n",
    "        \n",
    "\n",
    "        # 取り出し範囲更新\n",
    "        idx_start += batch_size\n",
    "        idx_end += batch_size\n",
    "    \n",
    "    # 検証データに対する損失を計算\n",
    "    y_pred_val = MLP_model(X_val)\n",
    "    loss_val = F.cross_entropy(y_pred_val, y_val)\n",
    "\n",
    "    # 損失、accuracyを記録\n",
    "    train_results[f\"epoch_{i}\"] = {\n",
    "        \"Loss_train\": cum_loss / num_batches,\n",
    "        \"Loss_val\": loss_val.item(),\n",
    "        \"Accuracy\": ( (torch.argmax(y_pred_val, dim=1) == y_val).sum() / len(y_val) ).item()\n",
    "    }\n",
    "\n",
    "    print(f'epoch_{i}: {train_results[f\"epoch_{i}\"]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
