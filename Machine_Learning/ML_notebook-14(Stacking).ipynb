{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# スタッキングの実装\n",
    "ここでは2値分類用のスタッキングのクラスを実装する。  \n",
    "scikit-learnにもスタッキング用のクラスが存在するが、学習時にKFold CVをしていない模様。なので過学習気味になる恐れ。    \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html\n",
    "\n",
    "本ドキュメントの参考資料：  \n",
    "[【本番編!!】米国データサイエンティストがやさしく教える機械学習超入門【Pythonで実践】](https://www.udemy.com/share/108nHI3@xpAI18mdRm1C_i4744C1DGbEtA6OMBG1WO06UV5L6j73HgS7l7uap7-gtqM2l5bf/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, label_binarize, OrdinalEncoder\n",
    "# import statsmodels.api as sma\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split ,LeaveOneOut, cross_val_score, KFold, RepeatedKFold,StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, log_loss, confusion_matrix,ConfusionMatrixDisplay, \\\n",
    "accuracy_score, precision_score, recall_score,precision_recall_curve,f1_score,roc_curve,auc,get_scorer_names,roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import linkage,dendrogram,fcluster\n",
    "from sklearn import tree\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# polarsでタイタニックデータを読み込み\n",
    "df = pl.from_pandas(sns.load_dataset('titanic'))\n",
    "\n",
    "# GBDTは欠損値の対処は不要だが、決定木やランダムフォレストは対処が必要。今回は単純に落とす。\n",
    "df = df.drop_nulls()\n",
    "\n",
    "# 学習データ、目的変数を定義\n",
    "X = df.drop(['survived', 'alive'])\n",
    "y = df.get_column('survived')\n",
    "\n",
    "# カテゴリ変数のカラム名をリスト化\n",
    "category_cols = X.select(pl.col([pl.Utf8, pl.Categorical, pl.Boolean])).columns\n",
    "\n",
    "# ラベルエンコーディング（LabelEncoderではなく、OrdinalEncoderを使う）\n",
    "oe = OrdinalEncoder()\n",
    "# pandasで返ってくるように指定。polarsは指定できない模様\n",
    "oe.set_output(transform='pandas')\n",
    "# カテゴリ変数をエンコーディング。polars.DFはそのまま入れられないのでpandasに変換する。\n",
    "X = X.with_columns( pl.from_pandas(oe.fit_transform(X.select(category_cols).to_pandas())) )\n",
    "\n",
    "# hold-out\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.to_pandas(), y.to_pandas(), test_size=0.3, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装前の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kfoldの定義\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "estimator = XGBClassifier(early_stopping_rounds=10, learning_rate=0.01, eval_metric='auc',random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.92778\n",
      "[1]\tvalidation_0-auc:0.93704\n",
      "[2]\tvalidation_0-auc:0.94074\n",
      "[3]\tvalidation_0-auc:0.94074\n",
      "[4]\tvalidation_0-auc:0.94074\n",
      "[5]\tvalidation_0-auc:0.94074\n",
      "[6]\tvalidation_0-auc:0.94074\n",
      "[7]\tvalidation_0-auc:0.94074\n",
      "[8]\tvalidation_0-auc:0.94074\n",
      "[9]\tvalidation_0-auc:0.94074\n",
      "[10]\tvalidation_0-auc:0.94074\n",
      "[11]\tvalidation_0-auc:0.94074\n",
      "[12]\tvalidation_0-auc:0.94074\n",
      "[0]\tvalidation_0-auc:0.77667\n",
      "[1]\tvalidation_0-auc:0.83167\n",
      "[2]\tvalidation_0-auc:0.83167\n",
      "[3]\tvalidation_0-auc:0.83167\n",
      "[4]\tvalidation_0-auc:0.83167\n",
      "[5]\tvalidation_0-auc:0.83167\n",
      "[6]\tvalidation_0-auc:0.83167\n",
      "[7]\tvalidation_0-auc:0.83167\n",
      "[8]\tvalidation_0-auc:0.83167\n",
      "[9]\tvalidation_0-auc:0.83167\n",
      "[10]\tvalidation_0-auc:0.83167\n",
      "[0]\tvalidation_0-auc:0.86727\n",
      "[1]\tvalidation_0-auc:0.87455\n",
      "[2]\tvalidation_0-auc:0.87818\n",
      "[3]\tvalidation_0-auc:0.87818\n",
      "[4]\tvalidation_0-auc:0.87818\n",
      "[5]\tvalidation_0-auc:0.87818\n",
      "[6]\tvalidation_0-auc:0.87818\n",
      "[7]\tvalidation_0-auc:0.87818\n",
      "[8]\tvalidation_0-auc:0.87818\n",
      "[9]\tvalidation_0-auc:0.87818\n",
      "[10]\tvalidation_0-auc:0.87818\n",
      "[11]\tvalidation_0-auc:0.87818\n",
      "[12]\tvalidation_0-auc:0.87818\n",
      "[0]\tvalidation_0-auc:0.67857\n",
      "[1]\tvalidation_0-auc:0.67208\n",
      "[2]\tvalidation_0-auc:0.67208\n",
      "[3]\tvalidation_0-auc:0.67208\n",
      "[4]\tvalidation_0-auc:0.67208\n",
      "[5]\tvalidation_0-auc:0.67208\n",
      "[6]\tvalidation_0-auc:0.67208\n",
      "[7]\tvalidation_0-auc:0.67208\n",
      "[8]\tvalidation_0-auc:0.67208\n",
      "[9]\tvalidation_0-auc:0.67208\n",
      "[10]\tvalidation_0-auc:0.67208\n",
      "[0]\tvalidation_0-auc:0.73264\n",
      "[1]\tvalidation_0-auc:0.73264\n",
      "[2]\tvalidation_0-auc:0.73264\n",
      "[3]\tvalidation_0-auc:0.73264\n",
      "[4]\tvalidation_0-auc:0.72743\n",
      "[5]\tvalidation_0-auc:0.72396\n",
      "[6]\tvalidation_0-auc:0.72743\n",
      "[7]\tvalidation_0-auc:0.72743\n",
      "[8]\tvalidation_0-auc:0.72743\n",
      "[9]\tvalidation_0-auc:0.72396\n",
      "[10]\tvalidation_0-auc:0.72396\n",
      "CPU times: user 19.1 s, sys: 2.09 s, total: 21.2 s\n",
      "Wall time: 1.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_pd = X.to_pandas()\n",
    "y_pd = y.to_pandas()\n",
    "y_pred_proba_li = []\n",
    "\n",
    "# Layer1\n",
    "for train_index, val_index in cv.split(X_pd):\n",
    "    X_train, X_val = X_pd.iloc[train_index], X_pd.iloc[val_index]\n",
    "    y_train, y_val = y_pd.iloc[train_index], y_pd.iloc[val_index]\n",
    "    \n",
    "    # モデル学習\n",
    "    eval_set = [(X_val, y_val)]\n",
    "    estimator.fit(X_train, y_train, eval_set=eval_set, verbose=True)\n",
    "    # 検証データ(学習に使っていないデータ)に対する予測値算出\n",
    "    y_pred_proba = estimator.predict_proba(X_val)\n",
    "\n",
    "    # 予測値を追加していく\n",
    "    y_pred_proba_li.append(y_pred_proba)\n",
    "\n",
    "result = np.concatenate(y_pred_proba_li)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "○ メモ  \n",
    "逐次concatenateする場合繰り返しconcatenateのオーバーヘッドがあるので、  \n",
    "リストでまとめてconcatするよりも時間がかかるらしい。（大規模データの場合）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.85264\n",
      "[1]\tvalidation_0-auc:0.85382\n",
      "[2]\tvalidation_0-auc:0.90184\n",
      "[3]\tvalidation_0-auc:0.86733\n",
      "[4]\tvalidation_0-auc:0.86838\n",
      "[5]\tvalidation_0-auc:0.86838\n",
      "[6]\tvalidation_0-auc:0.86838\n",
      "[7]\tvalidation_0-auc:0.86838\n",
      "[8]\tvalidation_0-auc:0.86838\n",
      "[9]\tvalidation_0-auc:0.86798\n",
      "[10]\tvalidation_0-auc:0.86838\n",
      "[11]\tvalidation_0-auc:0.86825\n",
      "[0]\tvalidation_0-auc:0.82661\n",
      "[1]\tvalidation_0-auc:0.82990\n",
      "[2]\tvalidation_0-auc:0.82910\n",
      "[3]\tvalidation_0-auc:0.82896\n",
      "[4]\tvalidation_0-auc:0.82896\n",
      "[5]\tvalidation_0-auc:0.82923\n",
      "[6]\tvalidation_0-auc:0.82937\n",
      "[7]\tvalidation_0-auc:0.82977\n",
      "[8]\tvalidation_0-auc:0.82977\n",
      "[9]\tvalidation_0-auc:0.82795\n",
      "[10]\tvalidation_0-auc:0.82795\n",
      "[0]\tvalidation_0-auc:0.87184\n",
      "[1]\tvalidation_0-auc:0.87270\n",
      "[2]\tvalidation_0-auc:0.87385\n",
      "[3]\tvalidation_0-auc:0.87457\n",
      "[4]\tvalidation_0-auc:0.87514\n",
      "[5]\tvalidation_0-auc:0.87514\n",
      "[6]\tvalidation_0-auc:0.87514\n",
      "[7]\tvalidation_0-auc:0.87514\n",
      "[8]\tvalidation_0-auc:0.87514\n",
      "[9]\tvalidation_0-auc:0.88182\n",
      "[10]\tvalidation_0-auc:0.88182\n",
      "[11]\tvalidation_0-auc:0.88168\n",
      "[12]\tvalidation_0-auc:0.88197\n",
      "[13]\tvalidation_0-auc:0.88628\n",
      "[14]\tvalidation_0-auc:0.88168\n",
      "[15]\tvalidation_0-auc:0.88685\n",
      "[16]\tvalidation_0-auc:0.88685\n",
      "[17]\tvalidation_0-auc:0.88614\n",
      "[18]\tvalidation_0-auc:0.88628\n",
      "[19]\tvalidation_0-auc:0.88606\n",
      "[20]\tvalidation_0-auc:0.88606\n",
      "[21]\tvalidation_0-auc:0.88592\n",
      "[22]\tvalidation_0-auc:0.88592\n",
      "[23]\tvalidation_0-auc:0.88621\n",
      "[24]\tvalidation_0-auc:0.88664\n",
      "[0]\tvalidation_0-auc:0.85350\n",
      "[1]\tvalidation_0-auc:0.85673\n",
      "[2]\tvalidation_0-auc:0.86110\n",
      "[3]\tvalidation_0-auc:0.86083\n",
      "[4]\tvalidation_0-auc:0.86204\n",
      "[5]\tvalidation_0-auc:0.86144\n",
      "[6]\tvalidation_0-auc:0.86292\n",
      "[7]\tvalidation_0-auc:0.86184\n",
      "[8]\tvalidation_0-auc:0.86251\n",
      "[9]\tvalidation_0-auc:0.86332\n",
      "[10]\tvalidation_0-auc:0.86332\n",
      "[11]\tvalidation_0-auc:0.86386\n",
      "[12]\tvalidation_0-auc:0.86399\n",
      "[13]\tvalidation_0-auc:0.86305\n",
      "[14]\tvalidation_0-auc:0.86305\n",
      "[15]\tvalidation_0-auc:0.86318\n",
      "[16]\tvalidation_0-auc:0.86372\n",
      "[17]\tvalidation_0-auc:0.86359\n",
      "[18]\tvalidation_0-auc:0.86359\n",
      "[19]\tvalidation_0-auc:0.86359\n",
      "[20]\tvalidation_0-auc:0.86318\n",
      "[21]\tvalidation_0-auc:0.86292\n",
      "[22]\tvalidation_0-auc:0.86292\n",
      "[0]\tvalidation_0-auc:0.87234\n",
      "[1]\tvalidation_0-auc:0.87311\n",
      "[2]\tvalidation_0-auc:0.87272\n",
      "[3]\tvalidation_0-auc:0.87222\n",
      "[4]\tvalidation_0-auc:0.87890\n",
      "[5]\tvalidation_0-auc:0.87813\n",
      "[6]\tvalidation_0-auc:0.87877\n",
      "[7]\tvalidation_0-auc:0.87775\n",
      "[8]\tvalidation_0-auc:0.87826\n",
      "[9]\tvalidation_0-auc:0.87775\n",
      "[10]\tvalidation_0-auc:0.87845\n",
      "[11]\tvalidation_0-auc:0.87833\n",
      "[12]\tvalidation_0-auc:0.88036\n",
      "[13]\tvalidation_0-auc:0.88030\n",
      "[14]\tvalidation_0-auc:0.88004\n",
      "[15]\tvalidation_0-auc:0.88004\n",
      "[16]\tvalidation_0-auc:0.87966\n",
      "[17]\tvalidation_0-auc:0.87979\n",
      "[18]\tvalidation_0-auc:0.87966\n",
      "[19]\tvalidation_0-auc:0.87903\n",
      "[20]\tvalidation_0-auc:0.87915\n",
      "[21]\tvalidation_0-auc:0.87903\n",
      "CPU times: user 41.7 s, sys: 3.89 s, total: 45.6 s\n",
      "Wall time: 3.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_pd = X.to_pandas()\n",
    "y_pd = y.to_pandas()\n",
    "# 予測値を入れる初期の空の配列を作成\n",
    "result_2 = np.empty((0, 2))\n",
    "\n",
    "# Layer1\n",
    "for train_index, val_index in cv.split(X_pd ,y_pd):\n",
    "    X_train, X_val = X_pd.iloc[train_index], X_pd.iloc[val_index]\n",
    "    y_train, y_val = y_pd.iloc[train_index], y_pd.iloc[val_index]\n",
    "    \n",
    "    # モデル学習\n",
    "    eval_set = [(X_val, y_val)]\n",
    "    estimator.fit(X_train, y_train, eval_set=eval_set, verbose=True)\n",
    "    # 検証データ(学習に使っていないデータ)に対する予測値算出\n",
    "    y_pred_proba = estimator.predict_proba(X_val)\n",
    "\n",
    "    # 予測値を追加していく\n",
    "    result_2 = np.concatenate((result, y_pred_proba))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 改善前\n",
    "下記は最初にスクラッチで実装したときのコード。  \n",
    "CVによってX,yの元のインデックスから変わってしまうことに気づかずに進めてしまった。  \n",
    "X_valに対するpredict_probaの結果をそのままリストに追加してconcatすると、  \n",
    "numpyに合わせてインデックスが０からふり直されてしまうことになる。  \n",
    "これを正しく行うには元々のpandasのインデックスを保持したまま予測結果を格納する必要がある。  \n",
    "また、XGB,LightGBMのearly stoppingのためだけにif文を実行するのは冗長な気がするので、  \n",
    "early stoppingはあきらめてもよいかも。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStackingClassifierCV:\n",
    "    def __init__(self, estimators, final_estimator=None, cv=None):\n",
    "        self.estimators = estimators\n",
    "        self.final_estimator = final_estimator\n",
    "        self.cv = cv\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # CVでの学習済みモデルからの予測結果格納用（Layer2学習用）\n",
    "        self.y_pred_dict_for_layer2 = {}\n",
    "        # テストデータに対する予測のためのモデル格納用\n",
    "        self.estimators_for_test = {}\n",
    "\n",
    "        # Layer1の学習    \n",
    "        for estimator_name, estimator in self.estimators:\n",
    "            # モデル名と予測値のリストを対応させる。\n",
    "            self.y_pred_dict_for_layer2[estimator_name] = []\n",
    "            # テストデータに対するLayer1での予測値格納用\n",
    "\n",
    "            # Layer2へ渡す特徴量生成のための学習\n",
    "            for train_index, val_index in self.cv.split(X):\n",
    "                # 学習用データと予測値算出用データに分ける\n",
    "                X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "                y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "                \n",
    "                if estimator_name == 'XGB':\n",
    "                    # XGBoostのモデル学習\n",
    "                    eval_set = [(X_val, y_val)]\n",
    "                    estimator.fit(X_train, y_train, eval_set=eval_set, verbose=True)\n",
    "                elif estimator_name == 'LGBM':\n",
    "                    # LightGBMのモデル学習\n",
    "                    eval_set = [(X_val, y_val)]\n",
    "                    callbacks = [lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation()]\n",
    "                    estimator.fit(X_train, y_train, eval_set=eval_set, callbacks=callbacks)\n",
    "                else:\n",
    "                    # 決定木のモデル学習\n",
    "                    estimator.fit(X_train, y_train)\n",
    "\n",
    "                # 学習に使わなかったデータに対する予測値を算出し、リストに追加\n",
    "                self.y_pred_dict_for_layer2[estimator_name].append(estimator.predict_proba(X_val))\n",
    "\n",
    "            # 全foldでの予測値を結合してそのモデルの最終的な予測値を算出\n",
    "            # !!! 結合した結果は元の入力データX,yと順番は異なってしまっていることに注意(CV時にシャッフルしているため)。\n",
    "            self.y_pred_dict_for_layer2[estimator_name] = np.concatenate(self.y_pred_dict_for_layer2[estimator_name])\n",
    "\n",
    "            # テストデータに対する予測のための学習\n",
    "            if estimator_name == 'XGB':\n",
    "                # XGBoostのモデル学習\n",
    "                X_train2, X_val2, y_train2, y_val2 = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "                eval_set = [(X_val2, y_val2)]\n",
    "                self.estimators_for_test[estimator_name] = estimator.fit(X_train2, y_train2, eval_set=eval_set, verbose=True)\n",
    "            elif estimator_name == 'LGBM':\n",
    "                # LightGBMのモデル学習\n",
    "                X_train2, X_val2, y_train2, y_val2 = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "                eval_set = [(X_val2, y_val2)]\n",
    "                callbacks = [lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation()]\n",
    "                self.estimators_for_test[estimator_name] = estimator.fit(X_train2, y_train2, eval_set=eval_set, callbacks=callbacks)\n",
    "            else:\n",
    "                # 決定木のモデル学習\n",
    "                self.estimators_for_test[estimator_name] = estimator.fit(X, y)\n",
    "        \n",
    "        # Layer1での予測値をまとめる（Layer2へ渡す用）。array[[モデル1の予測結果×2列, モデル2の予測結果×2列・・・]]の形式。\n",
    "        # concatenateで横に結合していく。予測結果が×２列になるのはpredict_probaの結果だから。\n",
    "        self.result_layer1 = np.concatenate(list(self.y_pred_dict_for_layer2.values()), axis=1)\n",
    "\n",
    "        # Layer2の学習。元々の特徴量＋layer1の結果を特徴量とする。\n",
    "        X_train_layer2 = np.concatenate([X, self.result_layer1], axis=1)\n",
    "        self.final_estimator.fit(X_train_layer2, y)\n",
    "\n",
    "        #return self.y_pred_dict_for_layer2\n",
    "        #return self.result_layer1\n",
    "\n",
    "    \n",
    "    def predict_proba(self, X_test):\n",
    "        # Layer1での学習済みモデルを使ってテストデータに対して予測\n",
    "        # result_layer1_for_testの予測値・モデルの並びとresult_layer1の並びは同じなので、そのままlayer2に渡してOK\n",
    "        result_layer1_for_test = [estimator.predict_proba(X_test) for _, estimator in self.estimators_for_test.items()]\n",
    "        #print(result_layer1_for_test)\n",
    "        result_layer1_for_test = np.concatenate(result_layer1_for_test, axis=1)\n",
    "        #print(result_layer1_for_test)\n",
    "        \n",
    "        # テストデータに対する最終的な予測（Layer2）。元々の特徴量＋layer1の結果を特徴量とする。\n",
    "        X_test_layer2 = np.concatenate([X_test, result_layer1_for_test], axis=1)\n",
    "        result = self.final_estimator.predict_proba(X_test_layer2)\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 呼び出し側\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "estimators = [\n",
    "    ('DT', tree.DecisionTreeClassifier(max_depth=2)),\n",
    "    ('XGB', XGBClassifier(early_stopping_rounds=10, learning_rate=0.01, eval_metric='auc',random_state=0)),\n",
    "    ('LGBM', lgb.LGBMClassifier(boosting_type='goss', max_depth=5, random_state=0))\n",
    "]\n",
    "final_estimator = LogisticRegression()\n",
    "\n",
    "# スタッキングのインスタンス生成\n",
    "model = MyStackingClassifierCV(estimators=estimators, final_estimator=final_estimator,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.80303\n",
      "[1]\tvalidation_0-auc:0.82121\n",
      "[2]\tvalidation_0-auc:0.82121\n",
      "[3]\tvalidation_0-auc:0.82121\n",
      "[4]\tvalidation_0-auc:0.82121\n",
      "[5]\tvalidation_0-auc:0.82121\n",
      "[6]\tvalidation_0-auc:0.81212\n",
      "[7]\tvalidation_0-auc:0.81212\n",
      "[8]\tvalidation_0-auc:0.78182\n",
      "[9]\tvalidation_0-auc:0.75152\n",
      "[10]\tvalidation_0-auc:0.73939\n",
      "[0]\tvalidation_0-auc:0.81818\n",
      "[1]\tvalidation_0-auc:0.81818\n",
      "[2]\tvalidation_0-auc:0.81818\n",
      "[3]\tvalidation_0-auc:0.81818\n",
      "[4]\tvalidation_0-auc:0.82955\n",
      "[5]\tvalidation_0-auc:0.82955\n",
      "[6]\tvalidation_0-auc:0.82955\n",
      "[7]\tvalidation_0-auc:0.82955\n",
      "[8]\tvalidation_0-auc:0.82955\n",
      "[9]\tvalidation_0-auc:0.81250\n",
      "[10]\tvalidation_0-auc:0.81250\n",
      "[11]\tvalidation_0-auc:0.81250\n",
      "[12]\tvalidation_0-auc:0.81250\n",
      "[13]\tvalidation_0-auc:0.81250\n",
      "[0]\tvalidation_0-auc:0.83333\n",
      "[1]\tvalidation_0-auc:0.85417\n",
      "[2]\tvalidation_0-auc:0.85417\n",
      "[3]\tvalidation_0-auc:0.85417\n",
      "[4]\tvalidation_0-auc:0.85417\n",
      "[5]\tvalidation_0-auc:0.85417\n",
      "[6]\tvalidation_0-auc:0.85417\n",
      "[7]\tvalidation_0-auc:0.85417\n",
      "[8]\tvalidation_0-auc:0.85417\n",
      "[9]\tvalidation_0-auc:0.85417\n",
      "[10]\tvalidation_0-auc:0.85417\n",
      "[11]\tvalidation_0-auc:0.85417\n",
      "[0]\tvalidation_0-auc:0.71333\n",
      "[1]\tvalidation_0-auc:0.73000\n",
      "[2]\tvalidation_0-auc:0.71000\n",
      "[3]\tvalidation_0-auc:0.73000\n",
      "[4]\tvalidation_0-auc:0.71000\n",
      "[5]\tvalidation_0-auc:0.72333\n",
      "[6]\tvalidation_0-auc:0.69667\n",
      "[7]\tvalidation_0-auc:0.72667\n",
      "[8]\tvalidation_0-auc:0.71333\n",
      "[9]\tvalidation_0-auc:0.72667\n",
      "[10]\tvalidation_0-auc:0.71333\n",
      "[11]\tvalidation_0-auc:0.72667\n",
      "[0]\tvalidation_0-auc:0.64931\n",
      "[1]\tvalidation_0-auc:0.59375\n",
      "[2]\tvalidation_0-auc:0.56597\n",
      "[3]\tvalidation_0-auc:0.56597\n",
      "[4]\tvalidation_0-auc:0.56597\n",
      "[5]\tvalidation_0-auc:0.56597\n",
      "[6]\tvalidation_0-auc:0.56597\n",
      "[7]\tvalidation_0-auc:0.56597\n",
      "[8]\tvalidation_0-auc:0.56597\n",
      "[9]\tvalidation_0-auc:0.56597\n",
      "[10]\tvalidation_0-auc:0.56597\n",
      "[0]\tvalidation_0-auc:0.71429\n",
      "[1]\tvalidation_0-auc:0.72143\n",
      "[2]\tvalidation_0-auc:0.71000\n",
      "[3]\tvalidation_0-auc:0.70429\n",
      "[4]\tvalidation_0-auc:0.70429\n",
      "[5]\tvalidation_0-auc:0.70429\n",
      "[6]\tvalidation_0-auc:0.70429\n",
      "[7]\tvalidation_0-auc:0.70429\n",
      "[8]\tvalidation_0-auc:0.70429\n",
      "[9]\tvalidation_0-auc:0.70429\n",
      "[10]\tvalidation_0-auc:0.70429\n",
      "[1]\tvalid_0's binary_logloss: 0.686294\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.673861\n",
      "[3]\tvalid_0's binary_logloss: 0.664223\n",
      "[4]\tvalid_0's binary_logloss: 0.657646\n",
      "[5]\tvalid_0's binary_logloss: 0.655938\n",
      "[6]\tvalid_0's binary_logloss: 0.654602\n",
      "[7]\tvalid_0's binary_logloss: 0.65703\n",
      "[8]\tvalid_0's binary_logloss: 0.658595\n",
      "[9]\tvalid_0's binary_logloss: 0.663487\n",
      "[10]\tvalid_0's binary_logloss: 0.667335\n",
      "[11]\tvalid_0's binary_logloss: 0.667335\n",
      "[12]\tvalid_0's binary_logloss: 0.667335\n",
      "[13]\tvalid_0's binary_logloss: 0.667335\n",
      "[14]\tvalid_0's binary_logloss: 0.667335\n",
      "[15]\tvalid_0's binary_logloss: 0.667335\n",
      "[16]\tvalid_0's binary_logloss: 0.667335\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's binary_logloss: 0.654602\n",
      "[1]\tvalid_0's binary_logloss: 0.540998\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.530399\n",
      "[3]\tvalid_0's binary_logloss: 0.517804\n",
      "[4]\tvalid_0's binary_logloss: 0.507342\n",
      "[5]\tvalid_0's binary_logloss: 0.491844\n",
      "[6]\tvalid_0's binary_logloss: 0.487342\n",
      "[7]\tvalid_0's binary_logloss: 0.480558\n",
      "[8]\tvalid_0's binary_logloss: 0.469684\n",
      "[9]\tvalid_0's binary_logloss: 0.463736\n",
      "[10]\tvalid_0's binary_logloss: 0.461882\n",
      "[11]\tvalid_0's binary_logloss: 0.461882\n",
      "[12]\tvalid_0's binary_logloss: 0.461882\n",
      "[13]\tvalid_0's binary_logloss: 0.461882\n",
      "[14]\tvalid_0's binary_logloss: 0.461882\n",
      "[15]\tvalid_0's binary_logloss: 0.461882\n",
      "[16]\tvalid_0's binary_logloss: 0.461882\n",
      "[17]\tvalid_0's binary_logloss: 0.461882\n",
      "[18]\tvalid_0's binary_logloss: 0.461882\n",
      "[19]\tvalid_0's binary_logloss: 0.461882\n",
      "[20]\tvalid_0's binary_logloss: 0.461882\n",
      "[21]\tvalid_0's binary_logloss: 0.461882\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's binary_logloss: 0.461882\n",
      "[1]\tvalid_0's binary_logloss: 0.616359\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.584174\n",
      "[3]\tvalid_0's binary_logloss: 0.557037\n",
      "[4]\tvalid_0's binary_logloss: 0.533945\n",
      "[5]\tvalid_0's binary_logloss: 0.517011\n",
      "[6]\tvalid_0's binary_logloss: 0.500183\n",
      "[7]\tvalid_0's binary_logloss: 0.488461\n",
      "[8]\tvalid_0's binary_logloss: 0.477253\n",
      "[9]\tvalid_0's binary_logloss: 0.468466\n",
      "[10]\tvalid_0's binary_logloss: 0.457841\n",
      "[11]\tvalid_0's binary_logloss: 0.457841\n",
      "[12]\tvalid_0's binary_logloss: 0.457841\n",
      "[13]\tvalid_0's binary_logloss: 0.457841\n",
      "[14]\tvalid_0's binary_logloss: 0.457841\n",
      "[15]\tvalid_0's binary_logloss: 0.457841\n",
      "[16]\tvalid_0's binary_logloss: 0.457841\n",
      "[17]\tvalid_0's binary_logloss: 0.457841\n",
      "[18]\tvalid_0's binary_logloss: 0.457841\n",
      "[19]\tvalid_0's binary_logloss: 0.457841\n",
      "[20]\tvalid_0's binary_logloss: 0.457841\n",
      "[21]\tvalid_0's binary_logloss: 0.457841\n",
      "[22]\tvalid_0's binary_logloss: 0.457841\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's binary_logloss: 0.457841\n",
      "[1]\tvalid_0's binary_logloss: 0.662147\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.643853\n",
      "[3]\tvalid_0's binary_logloss: 0.629689\n",
      "[4]\tvalid_0's binary_logloss: 0.618726\n",
      "[5]\tvalid_0's binary_logloss: 0.610287\n",
      "[6]\tvalid_0's binary_logloss: 0.603862\n",
      "[7]\tvalid_0's binary_logloss: 0.599155\n",
      "[8]\tvalid_0's binary_logloss: 0.595724\n",
      "[9]\tvalid_0's binary_logloss: 0.595271\n",
      "[10]\tvalid_0's binary_logloss: 0.593618\n",
      "[11]\tvalid_0's binary_logloss: 0.593618\n",
      "[12]\tvalid_0's binary_logloss: 0.593618\n",
      "[13]\tvalid_0's binary_logloss: 0.593618\n",
      "[14]\tvalid_0's binary_logloss: 0.593618\n",
      "[15]\tvalid_0's binary_logloss: 0.593618\n",
      "[16]\tvalid_0's binary_logloss: 0.593618\n",
      "[17]\tvalid_0's binary_logloss: 0.593618\n",
      "[18]\tvalid_0's binary_logloss: 0.593618\n",
      "[19]\tvalid_0's binary_logloss: 0.593618\n",
      "[20]\tvalid_0's binary_logloss: 0.593618\n",
      "[21]\tvalid_0's binary_logloss: 0.593618\n",
      "[22]\tvalid_0's binary_logloss: 0.593618\n",
      "[23]\tvalid_0's binary_logloss: 0.593618\n",
      "[24]\tvalid_0's binary_logloss: 0.593618\n",
      "[25]\tvalid_0's binary_logloss: 0.593618\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's binary_logloss: 0.593618\n",
      "[1]\tvalid_0's binary_logloss: 0.628601\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.607729\n",
      "[3]\tvalid_0's binary_logloss: 0.593433\n",
      "[4]\tvalid_0's binary_logloss: 0.579753\n",
      "[5]\tvalid_0's binary_logloss: 0.570748\n",
      "[6]\tvalid_0's binary_logloss: 0.561546\n",
      "[7]\tvalid_0's binary_logloss: 0.552682\n",
      "[8]\tvalid_0's binary_logloss: 0.548416\n",
      "[9]\tvalid_0's binary_logloss: 0.542162\n",
      "[10]\tvalid_0's binary_logloss: 0.549153\n",
      "[11]\tvalid_0's binary_logloss: 0.549153\n",
      "[12]\tvalid_0's binary_logloss: 0.549153\n",
      "[13]\tvalid_0's binary_logloss: 0.549153\n",
      "[14]\tvalid_0's binary_logloss: 0.549153\n",
      "[15]\tvalid_0's binary_logloss: 0.549153\n",
      "[16]\tvalid_0's binary_logloss: 0.549153\n",
      "[17]\tvalid_0's binary_logloss: 0.549153\n",
      "[18]\tvalid_0's binary_logloss: 0.549153\n",
      "[19]\tvalid_0's binary_logloss: 0.549153\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's binary_logloss: 0.542162\n",
      "[1]\tvalid_0's binary_logloss: 0.628133\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.60981\n",
      "[3]\tvalid_0's binary_logloss: 0.595633\n",
      "[4]\tvalid_0's binary_logloss: 0.582404\n",
      "[5]\tvalid_0's binary_logloss: 0.572513\n",
      "[6]\tvalid_0's binary_logloss: 0.565611\n",
      "[7]\tvalid_0's binary_logloss: 0.560827\n",
      "[8]\tvalid_0's binary_logloss: 0.559934\n",
      "[9]\tvalid_0's binary_logloss: 0.556517\n",
      "[10]\tvalid_0's binary_logloss: 0.557592\n",
      "[11]\tvalid_0's binary_logloss: 0.557592\n",
      "[12]\tvalid_0's binary_logloss: 0.557592\n",
      "[13]\tvalid_0's binary_logloss: 0.557592\n",
      "[14]\tvalid_0's binary_logloss: 0.557592\n",
      "[15]\tvalid_0's binary_logloss: 0.557592\n",
      "[16]\tvalid_0's binary_logloss: 0.557592\n",
      "[17]\tvalid_0's binary_logloss: 0.557592\n",
      "[18]\tvalid_0's binary_logloss: 0.557592\n",
      "[19]\tvalid_0's binary_logloss: 0.557592\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's binary_logloss: 0.556517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38508259, 0.61491741],\n",
       "       [0.52881099, 0.47118901],\n",
       "       [0.10296182, 0.89703818],\n",
       "       [0.10842325, 0.89157675],\n",
       "       [0.44995687, 0.55004313]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94     1\n",
       "18     0\n",
       "33     1\n",
       "98     1\n",
       "181    1\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9102564102564104"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_proba[:, 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一応、学習・予測はできたが、  \n",
    "インデックスの取り扱いは間違えているので修正が必要。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 改善後\n",
    "CVによる元のインデックスからの変更を加味して、  \n",
    "元データと同じサイズの空のnumpy配列を用意してそこにval_indexごとの予測結果を入れていくようにした。  \n",
    "（Polarsばかり使っているとインデックスを意識しなくなるが、CV時の学習ではちゃんと意識すること。  ）  \n",
    "また、XGBoost,LGBMのearly stoppingもなしにして汎用的にfitできるように書き換えている。  \n",
    "estimator_name,y_valは使ってないので不要かも。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStackingClassifierCV_mod:\n",
    "    def __init__(self, estimators, final_estimator=None, cv=None):\n",
    "        self.estimators = estimators\n",
    "        self.final_estimator = final_estimator\n",
    "        self.cv = cv\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # ------- Layer1の学習 ---------\n",
    "\n",
    "        # 新しい特徴量(Layer1の出力)を格納するための変数定義。（学習データ数、モデル数）というシェイプの０行列。\n",
    "        new_features_train = np.zeros((X.shape[0], len(self.estimators)))\n",
    "\n",
    "        for i, (estimator_name, estimator) in enumerate(self.estimators):\n",
    "\n",
    "            # Layer2へ渡す特徴量生成のための学習\n",
    "            for train_index, val_index in self.cv.split(X):\n",
    "                X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "                y_train, y_val = y.iloc[train_index], y.iloc[val_index]    \n",
    "\n",
    "                # モデルの学習\n",
    "                estimator.fit(X_train, y_train)\n",
    "\n",
    "                # 学習に使わなかったデータに対する予測値を算出し、新しい特徴量として格納\n",
    "                # predict_probaの１列目だけあればよいので[:, 1]とする\n",
    "                # val_indexの箇所にX_valの予測結果を格納することにより、元データの順序は守られる。\n",
    "                new_features_train[val_index, i] = estimator.predict_proba(X_val)[:, 1]\n",
    "\n",
    "            # テストデータに対する予測のための学習\n",
    "            # 全学習データを使って学習する。学習結果のモデルはself.estimatorsに反映されているので、別途格納する必要なし。\n",
    "            # （CVでの学習モデルが上書きされる形になる）\n",
    "            estimator.fit(X, y)\n",
    "        \n",
    "        # ------- Layer2の学習 ---------\n",
    "        # layer1の結果を特徴量とする。（元々の特徴量を加味してもOK）\n",
    "        self.final_estimator.fit(new_features_train, y)\n",
    "\n",
    "        # チェック用にLayer1の出力結果を返す\n",
    "        return new_features_train\n",
    "\n",
    "\n",
    "    def predict_proba(self, X_test):    \n",
    "        # 新しい特徴量(Layer1の出力)を格納するための変数定義（テストデータに対する予測用）。\n",
    "        new_features_test = np.zeros((X_test.shape[0], len(self.estimators)))\n",
    "        # Layer1での全データ学習済みモデルを使ってテストデータに対して予測\n",
    "        for i, (estimator_name, estimator) in enumerate(self.estimators):\n",
    "            new_features_test[:, i] = estimator.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # テストデータに対する最終的な予測（Layer2）。layer1の結果を特徴量とする。\n",
    "        result = self.final_estimator.predict_proba(new_features_test)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 呼び出し側\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "estimators = [\n",
    "    ('DT', tree.DecisionTreeClassifier(max_depth=2,random_state=0)),\n",
    "    ('rf', RandomForestClassifier(random_state=0)),\n",
    "    ('XGB', XGBClassifier(learning_rate=0.01, eval_metric='auc',random_state=0)),\n",
    "    ('LGBM', lgb.LGBMClassifier(boosting_type='goss', max_depth=5, random_state=0))\n",
    "]\n",
    "final_estimator = LogisticRegression()\n",
    "\n",
    "# スタッキングのインスタンス生成\n",
    "model = MyStackingClassifierCV_mod(estimators=estimators, final_estimator=final_estimator,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40425532, 0.35      , 0.55150753, 0.58320055],\n",
       "       [0.40425532, 0.7       , 0.48769337, 0.54981536],\n",
       "       [0.97959184, 1.        , 0.7927593 , 0.85259534],\n",
       "       [0.92857143, 0.91      , 0.76354849, 0.765261  ],\n",
       "       [0.40425532, 0.73      , 0.51422304, 0.44884073],\n",
       "       [0.92      , 0.82      , 0.71909469, 0.75841987],\n",
       "       [0.44230769, 0.36      , 0.25313053, 0.42866115],\n",
       "       [0.45652174, 0.57      , 0.60138512, 0.46196513],\n",
       "       [0.45652174, 0.39      , 0.26547787, 0.48403298],\n",
       "       [0.45945946, 0.21      , 0.5524525 , 0.53476594],\n",
       "       [0.45652174, 0.32      , 0.47820899, 0.47676944],\n",
       "       [0.44230769, 0.73      , 0.66333312, 0.5599008 ],\n",
       "       [0.25      , 0.61      , 0.4564794 , 0.75382181],\n",
       "       [0.44230769, 0.79      , 0.58188397, 0.5355605 ],\n",
       "       [0.34883721, 0.63      , 0.61693907, 0.56261661],\n",
       "       [0.40425532, 0.8       , 0.54500741, 0.44884073],\n",
       "       [0.97959184, 1.        , 0.7927593 , 0.88593721],\n",
       "       [0.40425532, 0.43      , 0.501369  , 0.48266832],\n",
       "       [0.92857143, 0.96      , 0.73289222, 0.83062845],\n",
       "       [0.34883721, 0.56      , 0.48381722, 0.54055551],\n",
       "       [0.34883721, 0.51      , 0.32982895, 0.44257722],\n",
       "       [0.45945946, 0.26      , 0.44944584, 0.41051505],\n",
       "       [0.45652174, 0.47      , 0.36298996, 0.46196513],\n",
       "       [0.92      , 0.85      , 0.66568345, 0.767673  ],\n",
       "       [0.97959184, 0.97      , 0.7927593 , 0.86437337],\n",
       "       [0.94339623, 0.83      , 0.76320887, 0.79729894],\n",
       "       [0.92857143, 0.93      , 0.7680155 , 0.765261  ],\n",
       "       [0.92857143, 0.99      , 0.7731986 , 0.765261  ],\n",
       "       [0.92      , 0.87      , 0.75947237, 0.82405282],\n",
       "       [0.94339623, 0.99      , 0.78727138, 0.85800893],\n",
       "       [0.45652174, 0.68      , 0.41422275, 0.48403298],\n",
       "       [0.34883721, 0.81      , 0.61133599, 0.44257722],\n",
       "       [0.94339623, 0.86      , 0.63925838, 0.85800893],\n",
       "       [0.92857143, 0.94      , 0.68608761, 0.83062845],\n",
       "       [0.92      , 0.93      , 0.77097917, 0.767673  ],\n",
       "       [0.92      , 1.        , 0.78229111, 0.82405282],\n",
       "       [0.45945946, 0.29      , 0.5524525 , 0.53476594],\n",
       "       [0.34883721, 0.38      , 0.38559031, 0.54055551],\n",
       "       [0.92      , 0.75      , 0.75129509, 0.70843144],\n",
       "       [0.45945946, 0.42      , 0.54376775, 0.53476594],\n",
       "       [0.97959184, 1.        , 0.7927593 , 0.88593721],\n",
       "       [1.        , 0.6       , 0.48152021, 0.44884073],\n",
       "       [0.92      , 0.86      , 0.67962861, 0.84697784],\n",
       "       [0.44230769, 0.33      , 0.24172544, 0.48011715],\n",
       "       [0.45945946, 0.58      , 0.59554404, 0.53476594],\n",
       "       [0.92857143, 0.99      , 0.7731986 , 0.765261  ],\n",
       "       [0.45945946, 0.32      , 0.31607464, 0.45842933],\n",
       "       [0.94230769, 0.76      , 0.46180069, 0.75382181],\n",
       "       [0.45652174, 0.58      , 0.4893052 , 0.47676944],\n",
       "       [0.94339623, 1.        , 0.78727138, 0.86377632],\n",
       "       [0.92857143, 0.9       , 0.5542624 , 0.765261  ],\n",
       "       [0.45652174, 0.41      , 0.68007886, 0.5614331 ],\n",
       "       [0.92857143, 1.        , 0.77844   , 0.83062845],\n",
       "       [1.        , 0.57      , 0.50551462, 0.54981536],\n",
       "       [0.        , 0.54      , 0.3847397 , 0.56689942],\n",
       "       [0.92      , 0.98      , 0.77097917, 0.767673  ],\n",
       "       [0.92      , 0.96      , 0.7705456 , 0.84697784],\n",
       "       [0.8       , 0.71      , 0.63930213, 0.56261661],\n",
       "       [0.94230769, 1.        , 0.7917909 , 0.8534867 ],\n",
       "       [0.45652174, 0.45      , 0.32167596, 0.54674694],\n",
       "       [0.44230769, 0.65      , 0.66333312, 0.5599008 ],\n",
       "       [0.40425532, 0.63      , 0.5284164 , 0.48266832],\n",
       "       [0.        , 0.15      , 0.34972626, 0.51178682],\n",
       "       [0.        , 0.16      , 0.31310096, 0.51178682],\n",
       "       [0.45945946, 0.78      , 0.70404702, 0.6108352 ],\n",
       "       [0.45945946, 0.6       , 0.63425791, 0.45842933],\n",
       "       [0.97959184, 1.        , 0.7927593 , 0.86437337],\n",
       "       [0.45945946, 0.63      , 0.46591058, 0.45842933],\n",
       "       [0.        , 0.6       , 0.3847397 , 0.55801322],\n",
       "       [0.34883721, 0.57      , 0.61693907, 0.56261661],\n",
       "       [0.25      , 0.76      , 0.4564794 , 0.75382181],\n",
       "       [0.97959184, 1.        , 0.7927593 , 0.85259534],\n",
       "       [0.34883721, 0.97      , 0.6570453 , 0.56261661],\n",
       "       [0.45652174, 0.23      , 0.40398228, 0.47676944],\n",
       "       [0.92      , 0.99      , 0.78496981, 0.82405282],\n",
       "       [0.44230769, 0.34      , 0.42241058, 0.46603094],\n",
       "       [0.92      , 0.98      , 0.78496981, 0.82405282],\n",
       "       [0.34883721, 0.33      , 0.29560506, 0.4206957 ],\n",
       "       [0.45652174, 0.49      , 0.67133814, 0.53952638],\n",
       "       [0.        , 0.74      , 0.5909971 , 0.79729894],\n",
       "       [0.94339623, 1.        , 0.78727138, 0.85800893],\n",
       "       [0.45945946, 0.18      , 0.32137713, 0.41051505],\n",
       "       [0.94339623, 1.        , 0.78727138, 0.85800893],\n",
       "       [0.45945946, 0.56      , 0.60699964, 0.6108352 ],\n",
       "       [0.44230769, 0.05      , 0.25013268, 0.474005  ],\n",
       "       [0.45652174, 0.29      , 0.30503982, 0.46920538],\n",
       "       [0.94339623, 0.67      , 0.73990756, 0.86377632],\n",
       "       [0.45945946, 0.97      , 0.67317379, 0.6108352 ],\n",
       "       [0.45945946, 0.22      , 0.4539468 , 0.41051505],\n",
       "       [0.        , 0.65      , 0.66533482, 0.85259534],\n",
       "       [0.8       , 0.64      , 0.60720229, 0.44257722],\n",
       "       [0.97959184, 1.        , 0.7927593 , 0.86437337],\n",
       "       [0.97959184, 0.87      , 0.69571042, 0.82596637],\n",
       "       [0.92      , 0.96      , 0.69624281, 0.84697784],\n",
       "       [0.92857143, 1.        , 0.77844   , 0.83062845],\n",
       "       [0.97959184, 0.98      , 0.7653088 , 0.88593721],\n",
       "       [0.92857143, 0.73      , 0.7502405 , 0.765261  ],\n",
       "       [0.94339623, 0.96      , 0.73990756, 0.86377632],\n",
       "       [0.97959184, 0.99      , 0.77191365, 0.82596637],\n",
       "       [0.40425532, 0.16      , 0.54400498, 0.58320055],\n",
       "       [0.97959184, 1.        , 0.7927593 , 0.88593721],\n",
       "       [0.97959184, 0.94      , 0.77191365, 0.82596637],\n",
       "       [0.45945946, 0.56      , 0.52839679, 0.53476594],\n",
       "       [0.94230769, 0.56      , 0.76204801, 0.73340961],\n",
       "       [0.44230769, 0.94      , 0.67225343, 0.51178682],\n",
       "       [0.97959184, 1.        , 0.77191365, 0.88593721],\n",
       "       [0.8       , 0.7       , 0.63930213, 0.56261661],\n",
       "       [0.92857143, 0.99      , 0.77730596, 0.765261  ],\n",
       "       [0.34883721, 0.5       , 0.43545741, 0.54055551],\n",
       "       [0.40425532, 0.7       , 0.67229223, 0.58320055],\n",
       "       [0.        , 0.22      , 0.34972626, 0.51178682],\n",
       "       [0.94230769, 0.58      , 0.46180069, 0.73340961],\n",
       "       [0.94230769, 1.        , 0.7917909 , 0.77970075],\n",
       "       [0.92      , 0.99      , 0.78496981, 0.84697784],\n",
       "       [0.94230769, 0.98      , 0.7917909 , 0.83832899],\n",
       "       [0.40425532, 0.68      , 0.51169181, 0.44884073],\n",
       "       [0.45945946, 0.45      , 0.52839679, 0.53476594],\n",
       "       [0.94230769, 0.8       , 0.64307517, 0.82328116],\n",
       "       [0.40425532, 0.23      , 0.26626846, 0.44884073],\n",
       "       [0.94339623, 1.        , 0.78727138, 0.85800893],\n",
       "       [0.34883721, 0.11      , 0.27182439, 0.4206957 ],\n",
       "       [0.44230769, 0.5       , 0.57130241, 0.41984128],\n",
       "       [0.45945946, 0.3       , 0.31337672, 0.45842933],\n",
       "       [0.34883721, 0.23      , 0.48114195, 0.54055551],\n",
       "       [0.92857143, 0.98      , 0.76355088, 0.83062845],\n",
       "       [0.94339623, 0.51      , 0.64048535, 0.85800893],\n",
       "       [0.97959184, 1.        , 0.7927593 , 0.82596637]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43423151, 0.56576849],\n",
       "       [0.56616054, 0.43383946],\n",
       "       [0.18996141, 0.81003859],\n",
       "       [0.1435601 , 0.8564399 ],\n",
       "       [0.48843374, 0.51156626],\n",
       "       [0.66581814, 0.33418186],\n",
       "       [0.53790878, 0.46209122],\n",
       "       [0.18702325, 0.81297675],\n",
       "       [0.15088874, 0.84911126],\n",
       "       [0.14445561, 0.85554439],\n",
       "       [0.58047206, 0.41952794],\n",
       "       [0.15753415, 0.84246585],\n",
       "       [0.15041664, 0.84958336],\n",
       "       [0.14445561, 0.85554439],\n",
       "       [0.38785889, 0.61214111],\n",
       "       [0.48502238, 0.51497762],\n",
       "       [0.37375941, 0.62624059],\n",
       "       [0.15114605, 0.84885395],\n",
       "       [0.14261931, 0.85738069],\n",
       "       [0.50422591, 0.49577409],\n",
       "       [0.16316144, 0.83683856],\n",
       "       [0.27403816, 0.72596184],\n",
       "       [0.14442245, 0.85557755],\n",
       "       [0.15405627, 0.84594373],\n",
       "       [0.21628915, 0.78371085],\n",
       "       [0.49889772, 0.50110228],\n",
       "       [0.46606927, 0.53393073],\n",
       "       [0.16659721, 0.83340279],\n",
       "       [0.51671636, 0.48328364],\n",
       "       [0.47924321, 0.52075679],\n",
       "       [0.53710407, 0.46289593],\n",
       "       [0.16130851, 0.83869149],\n",
       "       [0.15486187, 0.84513813],\n",
       "       [0.20556539, 0.79443461],\n",
       "       [0.15174103, 0.84825897],\n",
       "       [0.17502622, 0.82497378],\n",
       "       [0.14274602, 0.85725398],\n",
       "       [0.14261931, 0.85738069],\n",
       "       [0.55193626, 0.44806374],\n",
       "       [0.48970054, 0.51029946],\n",
       "       [0.46716142, 0.53283858],\n",
       "       [0.17208933, 0.82791067],\n",
       "       [0.42545228, 0.57454772],\n",
       "       [0.16835111, 0.83164889],\n",
       "       [0.45871735, 0.54128265],\n",
       "       [0.15263532, 0.84736468],\n",
       "       [0.14986446, 0.85013554],\n",
       "       [0.59147298, 0.40852702],\n",
       "       [0.44767372, 0.55232628],\n",
       "       [0.49827891, 0.50172109],\n",
       "       [0.46749823, 0.53250177],\n",
       "       [0.14024015, 0.85975985],\n",
       "       [0.51504312, 0.48495688],\n",
       "       [0.14785402, 0.85214598],\n",
       "       [0.15364036, 0.84635964]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8669871794871795"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_proba[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
