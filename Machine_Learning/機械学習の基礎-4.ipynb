{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>機械学習の基礎-4</b>\n",
    "EDA、前処理、特徴量エンジニアリング等の機械学習の一連のプロセスについてメモしておく。  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機械学習の一連の流れ\n",
    "大体は下記のような流れで進んでいく。  \n",
    "必ずしもこれ通りではない。  \n",
    "EDAとデータクリーニング、前処理（欠損値対応の部分）は通常のデータ分析業務でも大事。    \n",
    "\n",
    "1. EDA\n",
    "2. データクリーニング\n",
    "3. 前処理\n",
    "4. 特徴量エンジニアリング\n",
    "5. 特徴量選択\n",
    "6. ハイパーパラメータチューニング\n",
    "7. アンサンブル\n",
    "8. テストデータに対する評価  \n",
    "   \n",
    "(3.～6.は適宜繰り返す。単一のモデルに対してだけでなく、複数のモデルに対して行う。)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA(Exploratory data analysis、探索的データ分析)\n",
    "学習データのデータ構造、統計量の算出、欠損値・外れ値の確認、可視化等を行い、データの分布や性質を理解するプロセス。  \n",
    "ここで正しくデータを理解できないと正しい評価指標を選択できず、一連の作業が無駄になってしまうので非常に重要。  \n",
    "いわば機械学習の作業の前提を決める部分。  \n",
    "\n",
    "データクリーニングもEDAの作業として扱われることが多い。  \n",
    "ここでは不要なカラム（重複カラム、相関係数が1、欠損が多いカラム）や不要なデータ（重複データ、欠損が多いデータ、外れ値）など、  \n",
    "明らかに不要な部分や重複部分（意味合い的にも数値的にも重複しているデータ）を学習データから削除する。  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理(preprocessing)\n",
    "主に下記の作業が挙げられる。  \n",
    "* 欠損値対応(データクリーニングの中でやる場合も多い)\n",
    "* カテゴリカル変数のエンコーディング\n",
    "* 特徴量スケーリング"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 欠損値対応\n",
    "学習・テストデータの欠損値に対して何らかの処理を施し、モデルが学習・予測できる状態のデータにすること。  \n",
    "欠損値の対応方法として主に以下がある。  \n",
    "\n",
    "* 欠損値のあるレコードを落とす\n",
    "  * 手軽だが、貴重な学習データが減ってしまうので非推奨\n",
    "* 欠損のあるカラムの代表値（平均値、中央値、最頻値等）を欠損値に代入する。\n",
    "* 欠損値を新たなカテゴリとして扱う（カテゴリカラムの場合）\n",
    "* 欠損があるデータ以外を学習データとして、欠損値を予測して代入する。\n",
    "  * 詳細はML_notebook-16のkNNによる予測を参照。予測に使うモデルはkNNでなくてもOK。  \n",
    "  欠損がないレコードを学習データ（目的変数は欠損値を予測したいカラム。特徴量は欠損値があるカラム以外）とする。  \n",
    "\n",
    "欠損値対応する際は下記を留意すること。\n",
    "* なぜ欠損があるのかを考える\n",
    "  * ランダムネスがあるのか\n",
    "  * 人為的なものかシステム的なものか\n",
    "* 欠損値にも様々な値があることに注意(\"\", ?, 0, -, N/A, NaN, nan)\n",
    "* 欠損値を代入しても欠損があったことを表すフラグを残しておくのも学習に有効な場合がある。\n",
    "* 交差検証を行う際、欠損値を代表値で埋める作業は交差検証の中で行うこと。  \n",
    "  * すなわち交差検証における各Foldの学習データの代表値を算出し、それを検証データの欠損値を埋めるのに使うのが適切。  \n",
    "  全学習データを使って代表値を求めて欠損値を埋めてから交差検証を行うと、検証データの情報が学習データに漏れている(leakage)ことになってしまい、  \n",
    "  交差検証による評価が不当に高くなってしまう恐れがある。  \n",
    "  そのため、交差検証の各分割において学習データセットから代表値を計算し、その値を学習データと検証データの両方に適用することが望ましい。  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - カテゴリカル変数のエンコーディング\n",
    "交差検証する場合、基本的に交差検証の前にエンコーディングはやっておくべき。  \n",
    "でないと、学習データにあるクラスが検証データにはない（またはその逆）といったことが起こって予測時にエラーになる。  \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
