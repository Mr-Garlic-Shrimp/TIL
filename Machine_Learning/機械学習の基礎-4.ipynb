{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>機械学習の基礎-4</b>\n",
    "EDA、前処理、特徴量エンジニアリング等の機械学習の一連のプロセスについてメモしておく。  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機械学習の一連の流れ\n",
    "大体は下記のような流れで進んでいく。  \n",
    "必ずしもこれ通りではない。  \n",
    "EDAとデータクリーニング、前処理（欠損値対応の部分）は通常のデータ分析業務でも大事。    \n",
    "\n",
    "1. EDA\n",
    "2. データクリーニング\n",
    "3. 前処理\n",
    "4. 特徴量エンジニアリング\n",
    "5. 特徴量選択\n",
    "6. ハイパーパラメータチューニング\n",
    "7. アンサンブル\n",
    "8. テストデータに対する評価  \n",
    "   \n",
    "(3.～6.は適宜繰り返す。単一のモデルに対してだけでなく、複数のモデルに対して行う。)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA(Exploratory data analysis、探索的データ分析)\n",
    "学習データのデータ構造、統計量の算出、欠損値・外れ値の確認、可視化等を行い、データの分布や性質を理解するプロセス。  \n",
    "ここで正しくデータを理解できないと正しい評価指標を選択できず、一連の作業が無駄になってしまうので非常に重要。  \n",
    "いわば機械学習の作業の前提を決める部分。  \n",
    "\n",
    "データクリーニングもEDAの作業として扱われることが多い。  \n",
    "ここでは不要なカラム（重複カラム、相関係数が1、欠損が多いカラム）や不要なデータ（重複データ、欠損が多いデータ、外れ値）など、  \n",
    "明らかに不要な部分や重複部分（意味合い的にも数値的にも重複しているデータ）を学習データから削除する。  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理(preprocessing)\n",
    "主に下記の作業が挙げられる。  \n",
    "* 欠損値対応(データクリーニングの中でやる場合も多い)\n",
    "* カテゴリカル変数のエンコーディング\n",
    "* 特徴量スケーリング\n",
    "\n",
    "★重要：これら処理のfitは学習データに対してのみ行い、検証データ、テストデータにはtransformのみ行うこと！"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 欠損値対応\n",
    "学習・テストデータの欠損値に対して何らかの処理を施し、モデルが学習・予測できる状態のデータにすること。  \n",
    "欠損値の対応方法として主に以下がある。  \n",
    "\n",
    "* 欠損値のあるレコードを落とす\n",
    "  * 手軽だが、貴重な学習データが減ってしまうので非推奨\n",
    "* 欠損のあるカラムの代表値（平均値、中央値、最頻値等）を欠損値に代入する。\n",
    "  * 手軽で簡単だが、他の特徴量との関係を考慮していないため、正確性には欠ける。\n",
    "  * また、欠損値がランダムではなくなんらかの規則に従って欠損している場合は全く正しくない結果となってしまうので注意。\n",
    "  * とりあえず欠損値対応してベースラインの精度出したいときなどには有効。\n",
    "* 欠損値を新たなカテゴリとして扱う（カテゴリカラムの場合）\n",
    "* 欠損があるデータ以外を学習データとして、欠損値を予測して代入する。\n",
    "  * 詳細はML_notebook-16のkNNによる予測を参照。予測に使うモデルはkNNでなくてもOK。  \n",
    "  欠損がないレコードを学習データ（目的変数は欠損値を予測したいカラム。特徴量は欠損値があるカラム以外）とする。  \n",
    "\n",
    "欠損値対応する際は下記を留意すること。\n",
    "* なぜ欠損があるのかを考える\n",
    "  * ランダムネスがあるのか\n",
    "  * 人為的なものかシステム的なものか\n",
    "* 欠損値にも様々な値があることに注意(\"\", ?, 0, -, N/A, NaN, nan)\n",
    "* 欠損値を代入しても欠損があったことを表すフラグを残しておくのも学習に有効な場合がある。\n",
    "* 交差検証を行う際、欠損値を代表値で埋める作業は交差検証の中で行うこと。  \n",
    "  * すなわち交差検証における各Foldの学習データの代表値を算出し、それを検証データの欠損値を埋めるのに使うのが適切。  \n",
    "  全学習データを使って代表値を求めて欠損値を埋めてから交差検証を行うと、検証データの情報が学習データに漏れている(leakage)ことになってしまい、  \n",
    "  交差検証による評価が不当に高くなってしまう恐れがある。  \n",
    "  そのため、交差検証の各分割において学習データセットから代表値を計算し、その値を学習データと検証データの両方に適用することが望ましい。  \n",
    "  また、カテゴリ変数に欠損がある場合、基本的に欠損値対応後にダミー変数(One-Hot Encoding)に変換するべきであるから、これも交差検証の中で行う必要がある。  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - カテゴリカル変数(質的変数)のエンコーディング\n",
    "カテゴリカル変数のエンコーディング方法は主に以下。  \n",
    "\n",
    "* Label Encoding\n",
    "  * カテゴリごとに0から順に数字を割り当てる。  \n",
    "  大中小のような順序尺度に対して用いる。\n",
    "  <br></br>\n",
    "* One-hot Encoding\n",
    "  * 0, 1のダミー変数に変換するやつ。順序尺度・非順序尺度どちらにも使える。\n",
    "  * カテゴリの数だけカラムが増えるので、カテゴリ数が多い特徴量に対しては適用を避けるべき。  \n",
    "  * 線形モデルを使用する場合は多重共線性を考慮してダミー変数を一つ落とすこと。\n",
    "  <br></br>\n",
    "* Target Encoding (TS:target statisticsともいう)\n",
    "  * 目的変数の統計量（主に平均）をカテゴリとして代用する。（もしくは新たな特徴量として使う。）\n",
    "    * 例）全データ数100、色を表すカテゴリ変数が青で、目的変数が1（陽性）となる数が20のとき、20/100=0.2をラベルとして使う。  \n",
    "    あるカテゴリのときに目的変数が陽性となる割合をラベルにしているとも言える。  \n",
    "    多クラスの場合についてはML_notebook-18(Various_Encoding).ipynbを参照。  \n",
    "  * 目的変数が数値の場合も同様に平均をとる。\n",
    "  * カテゴリ変数に目的変数の情報を含めることができるので、One-hotなどよりも精度が高めになることが多いらしい。\n",
    "  * 順序尺度・非順序尺度どちらにも使え、One-Hot Encodingのように特徴量が増えることはないが、  \n",
    "    目的変数の情報を使っているので検証データを含めてエンコーディングしないように注意。（leakageになる）  \n",
    "    よってCVの際は、各foldでの学習データを基にfit,transformし、検証データではtransformだけすること。\n",
    "  * 最終的なテストデータに対するエンコーディングを行う際、手持ちの学習データ全てをfitするか、cv時の各foldで求めた平均値を使用して  \n",
    "    エンコーディングする。\n",
    "    <br></br>\n",
    "* Embeding Encoding\n",
    "  * ニューラルネットのembedding layerを使って学習する。\n",
    "  * 意味合い的に近いカテゴリ同士を数値的に近いものとして扱うことができる。\n",
    "  * 使用頻度はそんなに高くない。\n",
    "\n",
    "特徴量の特性に応じてそれぞれ使い分けること。  \n",
    "例えば、順序尺度ならLabel Encoding、順序尺度でないかつカテゴリ数の少ない特徴量ならOne-hot Encoding、  \n",
    "どちらにも当てはまりそうにないならTarget Encodingなど。  \n",
    "決定木やGBDTの場合、順序尺度でなくてもLabel Encodingを使ってOK.\n",
    "\n",
    "交差検証する場合、基本的に交差検証の前にエンコーディングはやっておくべき。  \n",
    "でないと、学習データにあるクラスが検証データにはない（またはその逆）といったことが起こって予測時にエラーになる。  \n",
    "しかし、カテゴリ変数に欠損があり、欠損値を代表値等で埋めて交差検証を行う場合はエンコーディングも交差検証の中で行う必要があることに注意。  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量エンジニアリング\n",
    "既にある特徴量から、予測に有益そうな特徴量を作り出すこと。  \n",
    "前処理やハイパーパラメータチューニングに時間をかけるよりも、  \n",
    "特徴量エンジニアリングに時間をかけた方が精度を高められることが多く、非常に重要なプロセスである。  \n",
    "下記のように色々な観点で作ってみてCVで検証してみるとよい。  \n",
    "* 日時情報から年、月、日、曜日、時、分、秒を切り出す等\n",
    "  * 現場では時刻データが付与されていることが多いため、よく使われる特徴量エンジニアリング手法の一つ。  \n",
    "  * 時系列データに限らず有効。  \n",
    "  * データの性質によっては注意が必要な場合がある。\n",
    "    * 例１）テストデータ2017年以降で学習データが2017年以前の場合。外挿することになり、精度が落ちる恐れがある。  \n",
    "      →2017年以降も2017年以前のyearに置き換える（同じ傾向と仮定する）か、yearを使わずに学習する必要あり。\n",
    "<br></br>\n",
    "* 多項式特徴量（${X_1}^2,X_1X_2$など）\n",
    "<br></br>\n",
    "* 数値をある範囲でbinningする（数値→カテゴリ）\n",
    "<br></br>\n",
    "* 四則演算（例えば、利益=売上-経費）\n",
    "  * ある特徴量に対して、別の特徴量や統計量との四則演算結果を新たな特徴量として生成する。\n",
    "    * カテゴリカル変数同士の結合も有効である。例えば、'blue'+'good'='blue_good'など。  \n",
    "      結合した特徴量に対してさらにtarget encodingを行うことにより、結合前よりも細分化したエンコーディングができる。  \n",
    "      この場合”blueかつgood”のカテゴリに対してtarget encodingをすることになり、カテゴリが細分化されるため。  \n",
    "      このとき、レコード数が少なすぎるとencoding後の値(目的変数の平均値)が異常になり、過小・過大評価してしまうので注意。  \n",
    "  * 特徴量の全組み合わせについてやる必要はなく、ドメイン的に意味のある特徴量を生成することが有効\n",
    "    * 例）利益 = 売上 - 経費\n",
    "  * 決定木ベースのモデルのように特徴量間の関係を捉えることができるモデルでも演算結果を明示的に学習させることで、  \n",
    "  精度が上がることがある。（決定木の気持ちになって考える。）\n",
    "<br></br>\n",
    "* 集約値\n",
    "  * 例えば、顧客テーブル（顧客IDが主キー）と取引記録テーブル（取引IDが主キー）があるとき、  \n",
    "    顧客一人に対して取引は複数は紐づく。このとき、紐づく取引の取引金額の合計を顧客に紐づけることで、  \n",
    "    新たな特徴量を生成できる。このように1:Nの関係のある２つのテーブルあるいはデータを集約して特徴量として扱うことができる。  \n",
    "    集約値はmin,max,sum,mean,median,stdなど。  \n",
    "    \n",
    "* ドメイン的に意味のある特徴量\n",
    "  * 例えば過去のデータセットには特徴量A,B,Cがあり、互いにドメイン的に関係のある特徴であるとする。  \n",
    "    一方で、タスクのために学習に使うデータセットにはA,Bはあるが、Cがないとする。  \n",
    "    このとき、前者のデータセットでA,BからCを予測するモデルを学習させておき、後者のA,Bに適用することで、Cを作成することができる。  \n",
    "    この手法は欠損値対応にも有効。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
