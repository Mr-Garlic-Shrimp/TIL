{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7240b8a3-dd38-489c-abbc-7cfeac3b0d1e",
   "metadata": {},
   "source": [
    "# <b>機械学習の基礎-3</b>\n",
    "アンサンブルや特徴量エンジニアリングについてメモしておく。  \n",
    "\n",
    "参考：  \n",
    "https://datawokagaku.com/ensemble/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe7a9ac-e946-4fb2-9667-14dec904f213",
   "metadata": {
    "tags": []
   },
   "source": [
    "## アンサンブル\n",
    "複数の機械学習モデルを組み合わせて予測する手法。  \n",
    "一般的に単一のモデルよりも精度が高く、実務での予測はアンサンブルが主流。  \n",
    "アンサンブルは主にバギング、ブースティング、スタッキングの3種類がある。\n",
    "\n",
    "組み合わせるモデルはそれぞれの相関が低い（似ていない）モデルが望ましく、できるだけ多種多様なモデルを用いる。  \n",
    "※弱学習器を使うのが良いようだが、KaggleではGBDTとニューラルネットの組み合わせを行っている例もあるので、  \n",
    "　必ずというわけではなさそう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d8a73-852a-421c-8791-d3c757a43946",
   "metadata": {},
   "source": [
    "### バギング(bagging: bootstrap aggregating)\n",
    "下記の流れで予測するのがバギング。\n",
    "1. 学習データを母集団として、重複を許してランダムに標本抽出する。    \n",
    "    （重複を許して： 同じレコードが何回出てきてもよい。）\n",
    "2. 抽出した学習データでモデルに学習させる。\n",
    "3. 学習させたいモデルの数だけ1.～2.を繰り返す（並列にモデルを複数個作るイメージ）。\n",
    "4. 全学習済みモデルの予測結果の多数決や確率の平均をとり、それをバギングによる予測結果とする。  \n",
    "\n",
    "学習データの一部しか使わずに学習させるため、high bias low variance気味になるので、  \n",
    "モデルには高varianceになりやすい決定木を用いることが多い。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfd29af-68ef-495c-8f08-336ae07af285",
   "metadata": {},
   "source": [
    "### ランダムフォレスト(Random Forest)\n",
    "バギングにおいて学習モデルに決定木を採用し、さらに特徴量を選択して学習させるアンサンブル手法。  \n",
    "それぞれの学習モデルで一部の学習データと特徴量を使わないことで、少し異なる決定木を複数作る。  \n",
    "（相関が低いモデルを作ることが狙い。アンサンブルでは多種多様なモデルを用いることが望ましいため。）"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c048ec3a-6057-4e68-89a2-02eb365051d8",
   "metadata": {},
   "source": [
    "### ブースティング(boosting)\n",
    "バギングと異なり、直列に弱学習器を順次作っていき、  \n",
    "それらの予測値ごとに重みをつけて足し合わせたものを最終的な予測値とする手法。  \n",
    "下記の流れのように、「残差を目的変数として学習し、その予測値で残差を埋める」というプロセスを繰り返して、  \n",
    "それぞれのモデルでの残差の予測値に学習率を掛けて足し合わせた結果を最終的な予測値とする。  \n",
    "\n",
    "<b>◎勾配ブースティング決定木（回帰）の例</b>  \n",
    "弱学習器（決定木）をN個作成する（N回のイテレーションを実施する）場合を考える。  \n",
    "t回目のイテレーションにおけるブースティング全体の予測値を$\\hat{F_t}(x)$、  \n",
    "このとき作成した決定木の予測結果を$\\hat{f_t}(x)$、  \n",
    "これの残差を$r_t$（$i$番目のデータの残差は$r_{ti}$）とおく。  \n",
    "また、最初のイテレーションでは$\\hat{F_0}(x)=\\bar{y}$とする。  \n",
    "このとき、予測値が常に0なので残差は目的変数に等しい（$r_{0i}=y_i$）。\n",
    "\n",
    "ブースティングでは以下の手順をN回繰り返す。(t = 1,2,...,N)\n",
    "\n",
    "1. 残差をt-1回目までの予測値で埋める。※t=1のときは初期値$\\hat{F_0}(x)$から計算。  \n",
    "   $r_{t} = y - \\eta\\hat{F_{t-1}}$\n",
    "\n",
    "2. 弱学習器$\\hat{f_t}$を学習データ$(X,r_{t})$で学習\n",
    "3. ひとつ前のイテレーション結果に予測値を足したものをt回目での予測結果とする。  \n",
    "   $\\eta$は過学習を防ぐための学習率。(学習をshrinkageさせる役割)  \n",
    "   $\\hat{F_t}(x) = \\hat{F_{t-1}}(x) + \\eta\\hat{f_{t}}(x)$\n",
    "   \n",
    "したがって、最終的な予測値（N回目の予測値）は下記のようになる。\n",
    "$$\\hat{F_N}(x) = \\hat{f_0}(x) + \\sum_{t=1}^N \\eta\\hat{f_t}(x)$$\n",
    "\n",
    "実は1.の残差は最小二乗法における損失の勾配を表す。  \n",
    "勾配ブースティングではこの勾配が小さくなるように学習している。  \n",
    "\n",
    "<b>◎勾配ブースティング決定木（2値分類）の例</b>  \n",
    "回帰の場合と初期値や予測値の使い方が異なる。  \n",
    "分類では最初のイテレーションの予測値は$\\hat{F_0}(x)=\\log(\\frac {\\bar{y}}{1-\\bar{y}})$とする。  \n",
    "これは陽性確率pを目的変数$y$の平均値とした場合の対数オッズ比である。  \n",
    "(損失関数LogLossを対数オッズ比で偏微分したときに目的変数$y$の平均値で最小になるため。)  \n",
    "この初期値を踏まえ、勾配ブースティング決定木による分類の流れは下記。  \n",
    "\n",
    "以下の手順をN回繰り返す。(t = 1,2,...,N)  \n",
    "\n",
    "1. 残差をt-1回目までの予測値で埋める。  \n",
    "   右辺の2項目はt-1回目までの予測値をシグモイド関数に入れて確率(以降$p$で表わす)の形にし、  \n",
    "   これを目的変数y(0 or 1)から引いたものを残差としている。\n",
    "   $$r_{t} = y - \\frac {1}{1+e^{-(F(t-1))}}$$  \n",
    "\n",
    "2. 弱学習器$\\hat{f_t}$を学習データ$(X,r_{t})$で学習  \n",
    "   学習し、葉の値が算出されるが、これをそのまま予測値としては使わず下記の値$f_t$で葉の値を置き換え、  \n",
    "   これを予測値とする。    \n",
    "   $$f_t(x_i) = \\frac {\\sum_{x_i\\in{R}} (y_i-p)} {\\sum_{x_i\\in{R}} p(1-p)}$$  \n",
    "   ※ $p = \\frac {1}{1+e^{-(F(t-1))}}$  \n",
    "   $x_i\\in{R}$はあるリージョン(=葉)$R$に落ちてくる学習データを表し、分子はそれらの残差の和、  \n",
    "   分母はt-1回目に予測値として出力された陽性率pと陰性率を乗じた値の和となっている。  \n",
    "   (この導出も損失関数から可能だが割愛。)  \n",
    "\n",
    "3. 回帰と同様、ひとつ前のイテレーション結果に予測値を足したものをt回目での予測結果とする。  \n",
    "   $\\eta$は過学習を防ぐための学習率。(学習をshrinkageさせる役割)  \n",
    "   $\\hat{F_t}(x) = \\hat{F_{t-1}}(x) + \\eta\\hat{f_{t}}(x)$  \n",
    "   確率の形で予測値を出力する場合は、$\\hat{F_t}(x)$をシグモイド関数にいれる。  \n",
    "\n",
    "<br></br>\n",
    "うまくいけばbiasとvarianceの両方を下げることができ、バギングよりも精度が高くなることが期待できる。  \n",
    "弱学習器には決定木を採用することが多い。  \n",
    "2023年3月時点で、このブースティングをベースとした勾配ブースティング決定木(GBDT)とニューラルネットが機械学習の主流。  \n",
    "(画像認識、自然言語処理等ではニューラルネット、テーブルデータではGBDTの方が使われるぽい。)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b663cd-8011-4f27-976b-da1b97488cfa",
   "metadata": {},
   "source": [
    "### AdaBoost(Adaptive Boosting)\n",
    "基本的なブースティングのアルゴリズムの一つ。  \n",
    "損失が大きい（上手く予測できなかった）データに重みをつけて次の学習で重点的に学習できるようにする手法。  \n",
    "データに重みをつけるというのは、通常は各データの損失を表す関数ごとに重み$\\omega_i$をつけるということ。  \n",
    "これを全データ分足し合わせたものが弱学習器の損失関数になり、これが最小になるように学習する。  \n",
    "$$L(x,y)=\\frac{1}{m}\\sum_{i=1}^m l(x_i,y_i)$$ \n",
    "この$l(x_i,y_i)$に対して損失の大きさに応じた重み$\\omega_i$がつけられる。  \n",
    "最初のイテレーションでは一律$\\omega_i=\\frac{1}{m}$がかけられ、  \n",
    "次のイテレーションから各データの損失の大きさに応じて$\\omega_i$は更新されていく。  \n",
    "また、弱学習器自体の重み$\\alpha$も損失に応じて計算され、  \n",
    "AdaBoostでの最終的な予測値はこの重みと各弱学習器の予測結果を掛け合わせた合計となる。  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc724b7-ad8e-4cfd-9330-e09590b71356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
